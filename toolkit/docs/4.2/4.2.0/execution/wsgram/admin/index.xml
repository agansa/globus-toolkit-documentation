<title>GT 4.0 WS GRAM : System Administrator's Guide</title>
<titleabbrev> System Administrator's Guide</titleabbrev>
 
<section id="s-wsgram-admin-introduction"><title>Introduction</title>

<para>This guide contains advanced configuration information
  for system administrators working with WS GRAM. It provides references to
  information on procedures typically performed by system administrators,
  including installation, configuring, deploying, and testing the
  installation. It also describes additional prerequisites and host settings
  necessary for WS GRAM operation. Readers should be familiar with the
  <ulink url="../../key/">Key Concepts</ulink> and
  <ulink url="../../key/WS_GRAM_Approach.html">Implementation Approach</ulink>
  for WS GRAM to understand the motivation for and interaction between the
  various deployed components.
</para>

<para>
  This information is in addition to the basic installation instructions in the
  <ulink url="../../admin/index.html">GT 4.0 System Administrator's Guide</ulink>.
</para>
</section><!-- introduction -->

<section id="s-wsgram-admin-installing"><title>Installation Requirements</title>

<section id="s-wsgram-admin-security"><title>Transport Level Security (TLS)</title>
<para>
  In order to use WS GRAM, the container must be started with Transport Level
  security.  The "-nosec" option should *not* be used with
  globus-start-container.
</para>
</section><!-- transport level security -->

<section id="s-wsgram-admin-sudo"><title>Functioning sudo</title> <para>
  WS GRAM requires that the <computeroutput>sudo</computeroutput> command is
  installed and functioning on the service host where WS GRAM software will
  execute.
</para>
<para>
  Authorization rules will need to be added to the
  <computeroutput>sudoers</computeroutput> file to allow the WS GRAM service
  account to execute (without a password) the scheduler adapter in the
  accounts of authorized GRAM users.  For configuration details, see the
  <ulink url="#configsudo">Configuring sudo</ulink> section.
</para>
</section><!-- functioning sudo -->

<section id="s-wsgram-admin-localscheduler"><title>Local scheduler</title>
<para> 
  WS GRAM depends on a local mechanism for starting and controlling jobs.
  Included in the WS GRAM software is a Fork "scheduler", which requires no
  special software installed to execute jobs on the local host.  However, to
  enable WS GRAM to execute and manage jobs to a batch scheduler, the scheduler
  software must be installed and configured prior to configuring WS GRAM.

  The WS GRAM scheduler adapters (interface to the batch schedulers) included
  in the GT 4.0 release are:
  <ulink url="http://www.openpbs.org/">PBS</ulink>,
  <ulink url="http://www.cs.wisc.edu/condor/">Condor</ulink>,
  <ulink url="http://www.platform.com/products/LSF/">LSF</ulink>

  For configuration details, see the
  <ulink url="#configuringscheduleradapters">Configuring scheduler adapters</ulink> section.
</para>

</section><!-- local scheduler -->

<section id="s-wsgram-admin-rft"><title>Reliable File Transfer Service (RFT)</title>
<para> 
  WS GRAM depends on RFT to perform file staging and cleanup directives in 
  a job description.  For configuration details, see the
  <ulink url="../../data/rft/admin/index.html">RFT admin guide</ulink>
  <emphasis>Important:</emphasis> Jobs requesting these functions will fail if
  RFT is not properly setup.
</para>
</section><!-- RFT -->

</section><!-- Installation Requirements -->


<section id="s-wsgram-admin-configuring"><title>Typical Configuration</title>

<section id="s-wsgram-admin-configsudo"><title>Configuring sudo</title>
<para>When the credentials of the service account and the job submitter are different
  (multi user mode), then GRAM will prepend a call to sudo to the local adapter
  callout command. <emphasis>Important:</emphasis> If sudo is not configured properly, the command
  and thus job will fail.</para>
<para>
  As <emphasis>root</emphasis>, here are the two lines to add to the
  /etc/sudoers file for each GLOBUS_LOCATION installation, where
  /opt/globus/GT4.0.0 should be replaced with the GLOBUS LOCATION for your
  installation:
<screen># Globus GRAM entries
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /etc/grid-security/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-job-manager-script.pl *
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /etc/grid-security/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-gram-local-proxy-tool *
</screen>
</para>
</section><!-- Configuring sudo -->

<section id="s-wsgram-admin-configuringscheduleradapters"><title>Configuring Scheduler Adapters</title>
<para>
  The WS GRAM scheduler adapters included in the release tarball
  are: PBS, Condor and LSF. To install, follow these steps (shown for pbs):

<screen>    % cd $GLOBUS_LOCATION\gt4.0.0-all-source-installer

    % ./configure --prefix=$GLOBUS_LOCATION --enable-wsgram-pbs

    % make

    % make install

</screen>
</para>
<para>
  Using PBS as the example, make sure the scheduler commands are in your
  path (qsub, qstat, pbsnodes).
</para>
<para> For PBS, another setup step is required to configure the remote shell for
  rsh access: 

<screen>

    % cd $GLOBUS_LOCATION/setup/globus

    % ./setup-globus-job-manager-pbs --remote-shell=rsh

</screen>
</para>
<para>
  The last thing is to define the <ulink url="WS_GRAM_Public_Interfaces.html#filesysmap">GRAM and GridFTP file system mapping</ulink> for PBS.  A default
  mapping in this file is created to allow simple jobs to run.  However, the
  actual file system mappings for your compute resource should be entered to
  ensure file staging is performed correctly, or jobs with erroneous file path
  directives are rejected.
</para>
<para>
  Done! You have added the PBS scheduler adapters to your GT installation.
</para>
</section><!-- enabling scheduler adapters -->

</section><!-- Typical Configuration -->

<section id="s-wsgram-admin-nondefaultinstall"><title>Non-default Configuration</title>

<section id="s-wsgram-admin-userproxy"><title>Non-default Credentials</title>
<para>
  To run the container using just a user proxy, instead of host creds,
  simply comment out the ContainerSecDesc parameter in this file <computeroutput>$GLOBUS_LOCATION/etc/globus_wsrf_core/server-config.wsdd</computeroutput> as
  follows:
<screen>
    &lt;!--
        &lt;parameter 
            name="containerSecDesc" 
            value="etc/globus_wsrf_core/global_security_descriptor.xml"/&gt;
     --&gt;
</screen>
  Running in personal mode (user proxy), another GRAM configuration setting
  is required. For GRAM to authorize the RFT service when performing
  staging functions, it needs to know the subject DN for verification. Here are
  the steps:
<screen>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-subject=
         "/DC=org/DC=doegrids/OU=People/CN=Stuart Martin 564720"
      </screen>
You can get your subject DN by running this command:
<screen>
	% grid-cert-info -subject
</screen>
</para>
</section><!-- Non-default Credentials -->

<section id="s-wsgram-admin-nondefaultgridftp"><title>Non-default GridFTP server </title>
<para>
  By default, the GridFTP server is assumed to run as root on localhost:2811.
  If this is not true for your site then change it by editting the GridFTP host
  and/or port in the <ulink url="WS_GRAM_Public_Interfaces.html#filesysmap">GRAM and GridFTP file system mapping</ulink> config file: <computeroutput>$GLOBUS_LOCATION/etc/gram-service/globus_gram_fs_map_config.xml</computeroutput>.
</para>

</section><!-- Non-default GridFTP server -->

<section id="s-wsgram-admin-nondefaultcontainerport"><title>Non-default container port</title>
<para>
  By default, the globus services will assume 8443 is the port the Globus
  container is using.  However the container can be run under a non-standard
  port, for example:
<screen>
	% globus-start-container -p 4321
</screen>
  When doing this, GRAM needs to be told the port to use to contact the RFT
  service, like so:
<screen>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-port="4321"
</screen>
</para>
</section><!-- Non-default container port -->

<section id="s-wsgram-admin-nondefaultgridmap"><title>Non-default gridmap</title>
<para>
  If you wish to specify a non-standard gridmap file in a multi-user
  installation, two basic configurations need to be changed:</para>

<itemizedlist>
    <listitem><para>$GLOBUS_LOCATION/etc/globus_wsrf_core/global_security_descriptor.xml
        <itemizedlist><listitem><simpara>As specified in the <ulink url="http://www-unix.globus.org/toolkit/docs/development/4.0-drafts/security/authzframe/security_descriptor.html#configGridmap">gridmap config</ulink> instructions, add a &lt;gridmap value="..."/&gt;
                element to the file appropriately.</simpara></listitem>
	</itemizedlist>
    </para></listitem>

    <listitem><para>/etc/sudoers
        <itemizedlist>
            <listitem><para>Add <screen>-g /path/to/grid-mapfile</screen> as the first argument to all instances of the <screen>globus-gridmap-and-exec</screen> command.
            </para></listitem>
        </itemizedlist>
    </para></listitem>
</itemizedlist>

<para>
Example:

<emphasis>global_security_descriptor.xml</emphasis>
<screen>
    ...

    &lt;gridmap value="/opt/grid-mapfile"/&gt;

    ...
</screen>
<emphasis>sudoers</emphasis>
<screen>
   ...

   # Globus GRAM entries
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /opt/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-job-manager-script.pl *
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /opt/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-gram-local-proxy-tool *

    ...
</screen>
</para>
</section><!-- Non-default gridmap file -->

<section id="s-wsgram-admin-nondefaultjoblimit"><title>Non-default job resource limit</title>
<para>The current limit on the number of job resources (both exec and multi)
allowed to exist at any one time is 1000.  This limit was chosen from
scalability tests as an appropriate precaution to avoid out-of-memory errors.
To change this value to, say, 150, use the setup-gram-service-common script as follows:</para>
<screen>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --max-job-limit="150"
</screen>
</section><!-- Non-default job resource limit -->

</section><!-- Non-default Configuration -->


<section id="s-wsgram-admin-testing"><title>Testing</title>
<para>See the WS GRAM <ulink url="../user/commandline_java_managed_globus_run.html#interactivemode">users guide</ulink> for information about submitting a test job.</para>
</section>


<section id="s-wsgram-admin-security_considerations"><title>Security Considerations </title>
&WS_GRAM_Security_Considerations_Frag;
</section>

<section id="s-wsgram-admin-troubleshooting"><title>Troubleshooting</title>
&WS_GRAM_Troubleshooting_Frag;
</section>

<section id="s-wsgram-admin-usage"><title>Usage statistics collection by the Globus Alliance</title>
&WS_GRAM_Usage_Statistics_Frag;
</section>
