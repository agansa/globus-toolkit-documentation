<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">

<article id="quickstart" xreflabel="GT Quickstart">
<title>GT <replaceable role="entity">shortversion</replaceable> Quickstart</title>
  <titleabbrev>Quickstart</titleabbrev>

<articleinfo id="q-intro"><abstract><title>Introduction</title>
<para>
This is a quickstart that shows a full installation of the Toolkit
on two Debian 3.1 machines.  It shows the installation of prereqs, 
installation of the toolkit, creation of certificates, and configuration
of services.  It is designed to supplement the main admin guide.
</para></abstract>
</articleinfo>

<section id="q-first"><title>Setting up the first machine</title>

<section id="q-prereq"><title>Pre-requisites</title>

<para>I will be installing all of the toolkit from source, so
I'm going to double-check my system for pre-requisites.  The full list
of prereqs is available at 
  <olink targetdoc="gtadmin" targetptr="gtadmin-prereq">Software Prerequisites</olink> in the GT <replaceable role="entity">shortversion</replaceable> Admin Guide.
</para>


<para>First I'll check for security libraries:
<screen>
<prompt>elephant %</prompt> <userinput>openssl version</userinput>
OpenSSL 0.9.7e 25 Oct 2004

<prompt>elephant %</prompt> <userinput>dpkg --list | grep zlib</userinput>
ii  zlib-bin       1.2.2-4.sarge. compression library - sample programs
ii  zlib1g         1.2.2-4.sarge. compression library - runtime
ii  zlib1g-dev     1.2.2-4.sarge. compression library - development
</screen>
openssl 0.9.7 (or newer, 0.9.8 is okay) and the zlib development libraries are required.
</para>
<note>
<para>The package names for zlib may vary for non-Debian systems.  The RPM name
we would look for is <filename>zlib-devel</filename>.</para>
</note>

<para>I also have j2sdk1.5-sun installed under /usr/lib/j2sdk1.5-sun from the sun-j2sdk1.5
dpkg:
<screen>
<prompt>elephant % </prompt><userinput>dpkg -S /usr/lib/j2sdk1.5-sun</userinput>
sun-j2sdk1.5: /usr/lib/j2sdk1.5-sun
</screen>
<note><para>Note that GT4.2 requires Java 5 or higher.  Java 1.4.2 is no longer supported.</para></note>
</para>

<para>I also have ant installed:
<screen>
<prompt>elephant % </prompt><userinput>ls /home/dsl/javapkgs/apache-ant-1.6.5/</userinput>
bin   INSTALL  LICENSE	    LICENSE.xerces  TODO
docs  KEYS     LICENSE.dom  NOTICE	    welcome.html
etc   lib      LICENSE.sax  README	    WHATSNEW
</screen>
</para>
<note><para>
Most RedHat and Fedora Core boxes already ship with ant, but it is configured to use gcj.
We don't want to use gcj!  To fix this, look for an /etc/ant.conf file.  If you have one,
rename it to /etc/ant.conf.orig for the duration of this quickstart.
</para></note>

<para>My system already has C/C++ compilers:
<screen>
<prompt>elephant % </prompt><userinput>which gcc</userinput>
/usr/bin/gcc
<prompt>elephant % </prompt><userinput>which g++</userinput>
/usr/bin/g++
</screen>
</para>

<para>GNU versions of tar/make/sed:
<screen>
<prompt>elephant % </prompt><userinput>tar --version</userinput>
tar (GNU tar) 1.14
Copyright (C) 2004 Free Software Foundation, Inc.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute it under the terms of the GNU General Public License;
see the file named COPYING for details.
Written by John Gilmore and Jay Fenlason.
<prompt>elephant % </prompt><userinput>sed --version</userinput>
GNU sed version 4.1.2
Copyright (C) 2003 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE,
to the extent permitted by law.
<prompt>elephant % </prompt><userinput>make --version</userinput>
GNU Make 3.80
Copyright (C) 2002  Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.
</screen>
</para>

<para>Finally, I have sudo and XML::Parser for GRAM:
<screen>
<prompt>elephant % </prompt><userinput>sudo -V</userinput>
Sudo version 1.6.8p7
<prompt>elephant % </prompt><userinput>locate XML/Parser.pm</userinput>
/usr/lib/perl5/XML/Parser.pm
</screen>
</para>
</section>

<section id="q-toolkit"><title>Building the Toolkit</title>
<para>
That completes the list of build prereqs, so now I will download the installer and build it.  The long version of these instructions is at <olink targetdoc="gtadmin" targetptr="gtadmin-install"/>.  First I created a globus user, and I will start the installation from that.  First I will setup my ANT_HOME and JAVA_HOME:
<screen>
<prompt>globus@elephant:~$ </prompt><userinput>export ANT_HOME=/home/dsl/javapkgs/apache-ant-1.6.5/</userinput>
<prompt>globus@elephant:~$ </prompt><userinput>export JAVA_HOME=/usr/lib/j2sdk1.5-sun</userinput>
<prompt>globus@elephant:~$ </prompt><userinput>export PATH=$ANT_HOME/bin:$JAVA_HOME/bin:$PATH</userinput>
<prompt>globus@elephant:~$</prompt> <userinput>tar xzf gt<replaceable role="entity">version</replaceable>-all-source-installer.tar.gz</userinput>
<prompt>globus@elephant:~$</prompt> <userinput>cd gt<replaceable role="entity">version</replaceable>-all-source-installer</userinput>
<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>./configure --prefix=/sandbox/globus/globus-<replaceable role="entity">version</replaceable>/</userinput>
checking build system type... i686-pc-linux-gnu
checking for javac... /usr/lib/j2sdk1.5-sun/bin/javac
checking for ant... /home/dsl/javapkgs/apache-ant-1.6.5//bin/ant
configure: creating ./config.status
config.status: creating Makefile
</screen>
</para>

<note><para>
The machine I am installing on doesn't have access to a scheduler.  If it did, I would have specified one of the wsgram scheduler options, 
  like <option>--enable-wsgram-condor</option>, <option>--enable-wsgram-lsf</option>, or <option>--enable-wsgram-pbs</option>.
</para></note>
<note><para>
I could have used the binary installer for this example, because Debian ia32 binaries are available.  
To make the quickstart more general, I decided to use source instead.
</para></note>

<para>Now it's time to build the toolkit:
<screen>
<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>make | tee installer.log</userinput>
cd gpt-3.2autotools2004 &amp;&amp; OBJECT_MODE=32 ./build_gpt
build_gpt ====&gt; installing GPT into /sandbox/globus/globus-<replaceable role="entity">version</replaceable>/
...
Time for a coffee break here, the build will take over an hour, possibly
longer depending on how fast your machine is
...
Your build completed successfully.  Please run make install.

<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>make install</userinput>
/sandbox/globus/globus-<replaceable role="entity">version</replaceable>//sbin/gpt-postinstall
...
..Done

<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> 
</screen>
</para>
</section>

<section id="q-security"><title>Setting up security on your first machine</title>
<para>
All of the work we're going to do now requires that we be authenticated and authorized.  We
use certificates for this purpose.  The Distinguished Name (DN) of a certificate will serve
as our authenticated identity.  That identity will then be authorized.  In this simple tutorial,
the authorization will happen in a file lookup.
</para>
<para>
We will need identites for both the services and users. For the services, we will use an identity
that is equal to their hostname.  For the users, we'll use their full name.  To create the certificates, 
we're going to use the SimpleCA that is distributed with the toolkit.  
Here's how we set it up, based on the instructions at
<olink targetdoc="gtadmin" targetptr="gtadmin-simpleca">SimpleCA Admin</olink>:
<screen>
<prompt>globus@elephant:~$</prompt> <userinput>export GLOBUS_LOCATION=/sandbox/globus/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>globus@elephant:~$</prompt> <userinput>source $GLOBUS_LOCATION/etc/globus-user-env.sh</userinput>
<prompt>globus@elephant:~$</prompt> <userinput>cd gt<replaceable role="entity">version</replaceable>-all-source-installer</userinput>
<prompt>globus@elephant:gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>perl gt-server-ca.pl -y</userinput>
Setting up /sandbox/globus/globus-4.2.0/
Please enter a password of at least four characters for the CA: 
Confirm password:
Creating a new simpleCA, logging to gt-server-ca.log...
Running setup-gsi...
Your CA hash is: 1bcdfe89
It is located at /sandbox/globus/globus-4.2.0//share/certificates/1bcdfe89.0
Your host DN is /O=Grid/OU=GlobusTest/OU=simpleCA-elephant.mcs.anl.gov/CN=host/elephant.mcs.anl.gov
The hostcert is located at /sandbox/globus/globus-4.2.0//etc/hostcert.pem
</screen>
<note><para>This will fail if /tmp is mounted noexec.  If you get a failure, you might try setting
GLOBUS_SH_TMP=`pwd` and trying again.
</para>
</note>
</para>

<para>
Here's what has happened:
<screen>
<prompt>globus@elephant:~$</prompt> <userinput>ls ~/.globus/</userinput>
simpleCA
<prompt>globus@elephant:~$</prompt> <userinput>ls ~/.globus/simpleCA/</userinput>
cacert.pem  globus_simple_ca_1bcdfe89_setup-0.18.tar.gz  newcerts
certs       grid-ca-ssl.conf                             private
crl         index.txt                                    serial
</screen>
That's the directory where my simpleCA has been created.  
  These files are all explained in the 
  <olink targetdoc="gsicAdmin">Security Admin Guide</olink>.
</para>

<para>
Our last step is to copy that signed certificate into <filename class="directory">/etc</filename>:
<screen>
<prompt>root@elephant:~#</prompt> <userinput>mv $GLOBUS_LOCATION/etc/host*.pem /etc/grid-security/</userinput>
</screen>
</para>

<para>
We'll make the containercerts owned by globus:
<screen>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>cp hostcert.pem containercert.pem</userinput>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>cp hostkey.pem containerkey.pem</userinput>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>chown globus:globus container*.pem</userinput>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>ls -l *.pem</userinput>
-rw-r--r--  1 globus globus 2724 2008-06-16 14:26 containercert.pem
-r--------  1 globus globus  887 2008-06-16 14:26 containerkey.pem
-rw-r--r--  1 root root     2724 2008-06-16 14:26 hostcert.pem
-rw-r--r--  1 root root     1404 2008-06-16 14:26 hostcert_request.pem
-r--------  1 root root      887 2008-06-16 14:26 hostkey.pem
</screen>
</para>
</section>

<section><title>Creating a MyProxy server</title>
<para>
We are going to create a MyProxy server on elephant, following the instructions at 
<olink targetdoc="myproxyAdmin" targetptr="myproxy-configuring">configuring MyProxy</olink>.  This will be used to
store our user's certificates.  Recall that so far we have made a host certificate, but we don't have any certificates for
end users yet.
<screen>
<prompt>root@elephant:~#</prompt> <userinput>export GLOBUS_LOCATION=/sandbox/globus/globus-<replaceable role="entity">version</replaceable>/</userinput>
<prompt>root@elephant:~#</prompt> <userinput>cp $GLOBUS_LOCATION/etc/myproxy-server.config /etc</userinput>
<prompt>root@elephant:~#</prompt> <userinput>vim /etc/myproxy-server.config </userinput>
<prompt>root@elephant:~#</prompt> <userinput>diff /etc/myproxy-server.config $GLOBUS_LOCATION/etc/myproxy-server.config</userinput>
15,21c15,21
&lt; accepted_credentials  "*"
&lt; authorized_retrievers "*"
&lt; default_retrievers    "*"
&lt; authorized_renewers   "*"
&lt; default_renewers      "none"
&lt; authorized_key_retrievers "*"
&lt; default_key_retrievers "none"
---
&gt; #accepted_credentials  "*"
&gt; #authorized_retrievers "*"
&gt; #default_retrievers    "*"
&gt; #authorized_renewers   "*"
&gt; #default_renewers      "none"
&gt; #authorized_key_retrievers "*"
&gt; #default_key_retrievers "none"
<prompt>root@elephant:~#</prompt> <userinput>cat $GLOBUS_LOCATION/share/myproxy/etc.services.modifications >> /etc/services </userinput>
<prompt>root@elephant:~#</prompt> <userinput>tail /etc/services </userinput>
binkp           24554/tcp                       # binkp fidonet protocol
asp             27374/tcp                       # Address Search Protocol
asp             27374/udp
dircproxy       57000/tcp                       # Detachable IRC Proxy
tfido           60177/tcp                       # fidonet EMSI over telnet
fido            60179/tcp                       # fidonet EMSI over TCP
# Local services
myproxy-server  7512/tcp                        # Myproxy server
<prompt>root@elephant:~#</prompt> <userinput>cp $GLOBUS_LOCATION/share/myproxy/etc.xinetd.myproxy /etc/xinetd.d/myproxy</userinput>
<prompt>root@elephant:~#</prompt> <userinput>vim /etc/xinetd.d/myproxy </userinput>
<prompt>root@elephant:~#</prompt> <userinput>cat /etc/xinetd.d/myproxy </userinput>
service myproxy-server
{
  socket_type  = stream
  protocol     = tcp
  wait         = no
  user         = root
  server       = /sandbox/globus/globus-<replaceable role="entity">version</replaceable>/sbin/myproxy-server
  env          = GLOBUS_LOCATION=/sandbox/globus/globus-<replaceable role="entity">version</replaceable> LD_LIBRARY_PATH=/sandbox/globus/globus-<replaceable role="entity">version</replaceable>/lib <co id="myproxy_ld-co" linkends="myproxy_ld"/>
  disable      = no
}
<prompt>root@elephant:~#</prompt> <userinput>/etc/init.d/xinetd reload</userinput>
Reloading internet superserver configuration: xinetd.
<prompt>root@elephant:~#</prompt> <userinput>netstat -an | grep 7512</userinput>
tcp        0      0 0.0.0.0:7512            0.0.0.0:*               LISTEN     
</screen>
<calloutlist>
   <callout arearefs="myproxy_ld-co" id="myproxy_ld" >
    <simpara>Your system may require a different environment variable than LD_LIBRARY_PATH if you're using MacOS X or IRIX</simpara>
   </callout>
</calloutlist>
</para>

<para>
Now that myproxy is setup, we'll get a usercert for bacon.  The globus user will add a new credential into myproxy.
I have to specify a full name
and a login name.  I'll be using "Charles Bacon" and "bacon" for my user.  I have to supply two different passwords.  The
first password is going to be the bacon user's password.  The second password has to be my SimpleCA password from when
I ran gt-server-ca.pl.
<screen>
<prompt>globus@elephant:</prompt> <userinput>myproxy-admin-adduser -c "Charles Bacon" -l bacon</userinput>
iA certificate request and private key is being created.
You will be asked to enter a PEM pass phrase.
This pass phrase is akin to your account password, 
and is used to protect your key file.
If you forget your pass phrase, you will need to
obtain a new certificate.

Generating a 1024 bit RSA private key
......................++++++
...++++++
writing new private key to '/tmp/myproxy_adduser_HUTit8/myproxy_adduser_key.pem'
Enter PEM pass phrase: <userinput>bacon's new password</userinput>
Verifying - Enter PEM pass phrase: <userinput>bacon's new password</userinput>
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Level 0 Organization [Grid]:Level 0 Organizational Unit [GlobusTest]:Level 1 Organizational Unit [simpleCA-elephant.mcs.anl.gov]:Level 2 Organizational Unit [mcs.anl.gov]:Name (e.g., John M. Smith) []:

A private key and a certificate request has been generated with the subject:

/O=Grid/OU=GlobusTest/OU=simpleCA-elephant.mcs.anl.gov/OU=mcs.anl.gov/CN=Charles Bacon

If the CN=Charles Bacon is not appropriate, rerun this
script with the -force -cn "Common Name" options.

Your private key is stored in /tmp/myproxy_adduser_HUTit8/myproxy_adduser_key.pem
Your request is stored in /tmp/myproxy_adduser_HUTit8/myproxy_adduser_cert_request.pem

Please e-mail the request to the Globus Simple CA 
You may use a command similar to the following:

  cat /tmp/myproxy_adduser_HUTit8/myproxy_adduser_cert_request.pem | mail 

Only use the above if this machine can send AND receive e-mail. if not, please
mail using some other method.

Your certificate will be mailed to you within two working days.
If you receive no response, contact Globus Simple CA at 

To sign the request
please enter the password for the CA key: <userinput>SimpleCA password</userinput>

The new signed certificate is at: /homes/globus/.globus/simpleCA//newcerts/05.pem

using storage directory /sandbox/globus/globus-4.2.0//var/myproxy
Credential stored successfully
</screen>

Our last act will be to create a grid-mapfile as root for authorization.  You can copy and paste the /O=Grid/OU=... 
subject name from the output above:
<screen>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>vim /etc/grid-security/grid-mapfile</userinput>
"/O=Grid/OU=GlobusTest/OU=simpleCA-elephant.mcs.anl.gov/OU=mcs.anl.gov/CN=Charles Bacon" bacon
</screen>
</para>
<note><para>
The globus user doesn't need a user certificate!  It's a dummy account that
we're using to own the GLOBUS_LOCATION.  When it starts the container, it
will use the containercert.  Only real people need user certs.
</para></note>

</section>

<section id="q-gridftp"><title>Set up GridFTP</title>
<para>
Now that we have our host and user credentials in place, we can start a service.  This setup comes from the 
  <olink targetdoc="gridftpAdmin">GridFTP Admin Guide</olink>.
<screen>
  <prompt>root@elephant:/etc/grid-security#</prompt> <userinput>vim /etc/xinetd.d/gridftp</userinput> <co id="q-xinetd-co" linkends="q-xinetd"/>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>cat /etc/xinetd.d/gridftp</userinput>
service gsiftp
{
instances               = 100
socket_type             = stream
wait                    = no
user                    = root
env                     += GLOBUS_LOCATION=/sandbox/globus/globus-<replaceable role="entity">version</replaceable>
env                     += LD_LIBRARY_PATH=/sandbox/globus/globus-<replaceable role="entity">version</replaceable>/lib <co  id="q-ld_lib-co"  linkends="q-ld_lib" />
server                  = /sandbox/globus/globus-<replaceable role="entity">version</replaceable>/sbin/globus-gridftp-server
server_args             = -i
log_on_success          += DURATION
disable                 = no
}
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>vim /etc/services </userinput>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>tail /etc/services </userinput>
vboxd           20012/udp
binkp           24554/tcp                       # binkp fidonet protocol
asp             27374/tcp                       # Address Search Protocol
asp             27374/udp
dircproxy       57000/tcp                       # Detachable IRC Proxy
tfido           60177/tcp                       # fidonet EMSI over telnet
fido            60179/tcp                       # fidonet EMSI over TCP

# Local services
myproxy-server  7512/tcp                        # Myproxy server
gsiftp          2811/tcp
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>/etc/init.d/xinetd reload</userinput>
Reloading internet superserver configuration: xinetd.
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>netstat -an | grep 2811</userinput>
tcp        0      0 0.0.0.0:2811            0.0.0.0:*               LISTEN     
</screen>
<calloutlist>
  <callout arearefs="q-xinetd-co"  id="q-xinetd" >
    <para>I already had xinetd installed:
    <screen>
bacon@elephant:~$ dpkg --list xinetd
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Installed/Config-files/Unpacked/Failed-config/Half-installed
|/ Err?=(none)/Hold/Reinst-required/X=both-problems (Status,Err: uppercase=bad)
||/ Name           Version        Description
+++-==============-==============-============================================
      ii  xinetd         2.3.13-3       replacement for inetd with many enhancements</screen>
      You can use inetd instead, see "Configuring the GridFTP server to run under xinetd/inetd" in <olink targetdoc="gridftpAdmin"/> for details.  
      For now, though, you might want to apt-get install xinetd.</para>
  </callout>
  <callout arearefs="q-ld_lib-co"  id="q-ld_lib" >
    <simpara>On MacOS X, this would be DYLD_LIBRARY_PATH.  Check your system documentation if LD_LIBARARY_PATH doesn't work on your system.</simpara>
  </callout>
</calloutlist>
   
</para>

<para>
Now the gridftp server is waiting for a request, so we'll run a client
and transfer a file:
<screen>
<prompt>bacon@elephant $</prompt> <userinput>myproxy-logon -s elephant</userinput>
Enter MyProxy pass phrase: <userinput>******</userinput>
A credential has been received for user bacon in /tmp/x509up_u1817.
<prompt>bacon@elephant $</prompt> <userinput>globus-url-copy gsiftp://elephant.mcs.anl.gov/etc/group file:///tmp/bacon.test.copy</userinput>
<prompt>bacon@elephant $</prompt> <userinput>diff /tmp/bacon.test.copy /etc/group</userinput>
<prompt>bacon@elephant $</prompt> <userinput></userinput>
</screen>
</para>

<para>Okay, so the GridFTP server works.  If you had trouble, check the
  security troubleshooting section in the <olink targetdoc="gsicAdmin">Security Admin Guide</olink>.  Now we can move on to starting the webservices container.
</para>
</section>

<section id="q-container"><title>Starting the webservices container</title>

<para>Now we'll setup an /etc/init.d entry for the webservices container.  You can find more details about the container at 
  <olink targetdoc="javawscoreAdmin" />.
<screen>
<prompt>root@elephant:~#</prompt> <userinput>cp $GLOBUS_LOCATION/etc/init.d/globus-ws-java-container /etc/init.d</userinput>
<prompt>root@elephant:~#</prompt> <userinput>/etc/init.d/globus-ws-java-container start</userinput>
Starting Globus container. PID: 29985
</screen> 
</para>

<para>At this point, we can use one of the sample clients/services to interact with the container:
<screen>
<prompt>bacon@elephant $</prompt> <userinput>globus-check-remote-environment -s https://localhost:8443</userinput>

### Remote Endpoint Version Information ###
Axis Version on remote endpoint https://localhost:8443:
Apache Axis version: 1.4
Built on Mar 01, 2007 (10:42:15 CST)

Java WS Core Version on remote endpoint https://localhost:8443:
4.2.0

</screen>
That is the expected output, so it looks like the container is up and running. 
</para>
</section>

<section id="q-rft"><title>Configuring RFT</title>
<para>
We will use the globus-crft command to start a reliable file transfer.  It takes an input file whose syntax is one pair
of URLs per line.  It will use RFT to manage the transfer of all the URLs in the transfer file.  For this example, we'll
just move a single file:
<screen>
<prompt>bacon@elephant $ </prompt><userinput>cat transfer</userinput>
gsiftp://elephant.mcs.anl.gov/etc/group gsiftp://elephant.mcs.anl.gov/tmp/asdf
<prompt>bacon@elephant $ </prompt><userinput>globus-crft -ez -f transfer</userinput>
Communicating with delegation service.
Creating the RFT service.
Starting the RFT service.
Waiting for the RFT transfers to complete.
Transfered 1 of 1			| Status: Done       

<prompt>bacon@elephant $</prompt> <userinput>diff /etc/group /tmp/asdf</userinput>
<prompt>bacon@elephant $</prompt> 
</screen>
RFT did its job, starting up a reliable transfer and notifying us of the status and results.  The globus-crft command
has many options.  You may want to explore using it asynchronously, see the -help for details.
</para>
</section>

  <section id="q-gram"><title>Setting up GRAM4</title>
<para>
Now that we have GridFTP and RFT working, we can setup GRAM for resource
management.  First we have to setup sudo so the globus user can start jobs
  as a different user.  For reference, you can see the <olink targetdoc="gram4Admin" />.
  <screen>
    <prompt>root@elephant:~#</prompt> <userinput>visudo</userinput>
<prompt>root@elephant:~#</prompt> <userinput>cat /etc/sudoers </userinput>
Runas_Alias GLOBUSUSERS = ALL, !root;
globus ALL=(GLOBUSUSERS) NOPASSWD: /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-gridmap-and-execute
-g /etc/grid-security/grid-mapfile /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-job-manager-script.pl *
globus  ALL=(GLOBUSUSERS) NOPASSWD: /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-gridmap-and-execute
-g /etc/grid-security/grid-mapfile /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-gram-local-proxy-tool *
</screen>
Make sure they're all on one line.  I split them up in the HTML to keep the page width down.  With that addition, we can now run jobs:
<screen>
<prompt>bacon@elephant $</prompt> <userinput>globusrun-ws -submit -c /bin/true</userinput>
Submitting job...Done.
Job ID: uuid:a4b5e324-3bec-11dd-95ac-003048241085
Termination time: 06/16/3008 21:39 GMT
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
<prompt>bacon@elephant $</prompt> <userinput>echo $?</userinput>
0
<prompt>bacon@elephant $</prompt> <userinput>globusrun-ws -submit -c /bin/false</userinput>
Submitting job...Done.
Job ID: uuid:b49462c0-3bec-11dd-9441-003048241085
Termination time: 06/16/3008 21:39 GMT
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.

<prompt>bacon@elephant $</prompt> <userinput>echo $?</userinput>
1
</screen>
Success.  Now we've got a working GRAM installation.
</para>
</section>
</section>

<section id="q-second"><title>Setting up your second machine</title>
<section id="q-prereq2"><title>Setting up your second machine: Prereqs</title>
<para>
Alas, it's not much of a grid with just one machine.  So let's start up
on another machine and add it to this little test grid.  For a change of
pace, I'm going to use the binary installer on this machine.  
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>tar xzf gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer.tar.gz</userinput>
<prompt>globus@cognito:~$ </prompt><userinput>export ANT_HOME=/home/dsl/javapkgs/apache-ant-1.6.5/</userinput>
<prompt>globus@cognito:~$ </prompt><userinput>export JAVA_HOME=/usr/lib/j2sdk1.5-sun</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>export PATH=$ANT_HOME/bin:$JAVA_HOME/bin:$PATH</userinput>
</screen>
</para>

</section>

<section id="q-toolkit2"><title>Setting up your second machine: Installation</title>
<para>
Now we can install from binaries:
<screen>

<prompt>globus@cognito:~/gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer$</prompt> <userinput>./configure \
   --prefix=/usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
checking for javac... /usr/lib/j2sdk1.5//bin/javac
checking for ant... /home/dsl/javapkgs/apache-ant-1.6.5//bin/ant
configure: creating ./config.status
config.status: creating Makefile
<prompt>globus@cognito:~/gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer$</prompt> <userinput>make</userinput>
cd gpt-3.2autotools2004 &amp;&amp; OBJECT_MODE=32 ./build_gpt
...
Binaries are much faster!  This is done in less than 10 minutes.
...
tar -C /usr/local/globus-<replaceable role="entity">version</replaceable> -xzf binary-trees/globus_wsrf_rft_test-*/*.tar.gz
tar -C /usr/local/globus-<replaceable role="entity">version</replaceable> -xzf binary-trees/globus_rendezvous-*/*.tar.gz
Your build completed successfully.  Please run make install.
<prompt>globus@cognito:~/gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer$</prompt> <userinput>make install</userinput>
ln -s /usr/local/globus-<replaceable role="entity">version</replaceable>/etc/gpt/packages /usr/local/globus-<replaceable role="entity">version</replaceable>/etc/globus_packages
...
config.status: creating fork.pm
..Done
</screen>
</para>
</section>

<section id="q-security2"><title>Setting up your second machine: Security</title>
<para>Now let's get security setup on the second machine.  We're going to just add trust for the original simpleCA to this new machine, there's no need to create a new one.  All we need to do is copy the $GLOBUS_LOCATION/share/certificates from our
first machine to our second:
<screen>
<prompt>globus@crunch:~$</prompt> <userinput>export GLOBUS_LOCATION=/usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>globus@crunch:~$</prompt> <userinput>scp -r elephant:/sandbox/globus/globus-4.2.0/share/certificates $GLOBUS_LOCATION/share</userinput>
</screen>

We're going to create the host certificate for cognito, but we create it on elephant:
<screen>
<prompt>globus@elephant:~$</prompt> <userinput>myproxy-admin-addservice -c "cognito.mcs.anl.gov" -l cognito</userinput>
</screen>

Then as root on cognito:
<screen>
<prompt>root@cognito:~#</prompt> <userinput>export GLOBUS_LOCATION=/usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>root@cognito:~#</prompt> <userinput>source $GLOBUS_LOCATION/globus-user-env.sh</userinput>
<prompt>root@cognito:~#</prompt> <userinput>myproxy-retrieve -s elephant -k cognito.mcs.anl.gov -l cognito</userinput>
Enter MyProxy pass phrase:<userinput>******</userinput>
Credentials for bacon have been stored in
/etc/grid-security/hostcert.pem and
/etc/grid-security/hostkey.pem.
<prompt>root@cognito:~#</prompt> <userinput>cd /etc/grid-security</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>cp hostcert.pem containercert.pem</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>cp hostkey.pem containerkey.pem</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>chown globus:globus container*.pem</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>ls -l *.pem</userinput>
-rw-------  1 root root 912 2008-06-19 13:50 containercert.pem
-rw-------  1 root root 887 2008-06-19 13:50 containerkey.pem
-rw-------  1 root root 912 2008-06-19 13:45 hostcert.pem
-rw-------  1 root root 887 2008-06-19 13:45 hostkey.pem
<prompt>root@cognito:/etc/grid-security# </prompt><userinput>myproxy-destroy -s  elephant -k cognito.mcs.anl.gov -l cognito</userinput>
MyProxy credential 'cognito.mcs.anl.gov' for user cognito was successfully removed.
</screen>
There.  Now cognito is setup with host and container certs, and it trusts the CA of my grid.  The last step for root is to create a grid-mapfile for myself again:
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>vim grid-mapfile</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>cat grid-mapfile </userinput>
"/O=Grid/OU=GlobusTest/OU=simpleCA-elephant.mcs.anl.gov/OU=mcs.anl.gov/CN=Charles Bacon" bacon
</screen>
</para>
</section>

<section id="q-gridftp2"><title>Setting up your second machine: GridFTP</title>
<para>
GridFTP setup on the second machine is identical to the first.  I'll just
list the commands here, see <olink targetptr="q-gridftp"/> for the file contents, or just copy them from the first machine.
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>vim /etc/xinetd.d/gridftp</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>vim /etc/services </userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>/etc/init.d/xinetd reload</userinput>
Reloading internet superserver configuration: xinetd.
</screen>
Now we can test it:
<screen>
<prompt>cognito %</prompt> <userinput>setenv GLOBUS_LOCATION /usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>cognito %</prompt> <userinput>source $GLOBUS_LOCATION/etc/globus-user-env.csh</userinput>
<prompt>cognito %</prompt> <userinput>myproxy-logon -s elephant</userinput>
Enter MyProxy pass phrase: <userinput>******</userinput>
A credential has been received for user bacon in /tmp/x509up_u1817.
<prompt>cognito %</prompt> <userinput>globus-url-copy gsiftp://cognito.mcs.anl.gov/etc/group \
   gsiftp://elephant.mcs.anl.gov/tmp/from-cognito</userinput>
</screen>
That was a slightly fancier test than I ran on elephant.  In this case, I did a third-party transfer between two GridFTP servers.  It worked, so I have the local and remote security setup correctly.
</para>
</section>

<section id="q-container2"><title>Setting up your second machine: Webservices</title>
<para>
Setting up the container on the second machine is a lot like the first.  I'll list the commands here.  See <olink targetptr="q-container"/>, or you can just copy the files from the first machine.  First globus creates the start-stop script:
<screen>
<prompt>root@cognito:~#</prompt> <userinput>cp $GLOBUS_LOCATION/etc/init.d/globus-ws-java-container /etc/init.d</userinput>
<prompt>root@cognito:~#</prompt> <userinput>/etc/init.d/globus-ws-java-container start</userinput>
Starting Globus container. PID: 19745
</screen>
</para>
</section>

  <section id="q-gram2"><title>Setting up your second machine: GRAM4</title>
<para>
As with last time, we'll need to setup the sudoers.  See <olink targetptr="q-gram"/> for the sudo contents, or copy the sudoers from the first machine.
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>visudo</userinput>
</screen>

Now we can submit a staging job.  This job will copy the /bin/echo command from cognito to a file called $HOME/my_echo.  Then
it runs it with some arguments, and captures the stderr/stdout.  Finally, it will clean up the my_echo file when execution is
done.
<screen>
<prompt>cognito %</prompt> <userinput>vim a.rsl</userinput>
<prompt>cognito %</prompt> <userinput>cat a.rsl</userinput>
cognito % cat a.rsl
<![CDATA[
<job>
    <executable>my_echo</executable>
    <directory>${GLOBUS_USER_HOME}</directory>
    <argument>Hello</argument>
    <argument>World!</argument>
    <stdout>${GLOBUS_USER_HOME}/stdout</stdout>
    <stderr>${GLOBUS_USER_HOME}/stderr</stderr>
    <fileStageIn>
        <transfer>
            <sourceUrl>gsiftp://cognito.mcs.anl.gov:2811/bin/echo</sourceUrl>
            <destinationUrl>file:///${GLOBUS_USER_HOME}/my_echo</destinationUrl>
        </transfer>
    </fileStageIn>
    <fileCleanUp>
        <deletion>
            <file>file:///${GLOBUS_USER_HOME}/my_echo</file>
        </deletion>
    </fileCleanUp>
</job>
]]>
<prompt>cognito %</prompt> <userinput>globusrun-ws -submit -S -f a.rsl</userinput>
Delegating user credentials...Done.
Submitting job...Done.
Job ID: uuid:1223d7e6-3e35-11dd-a209-003048241085
Termination time: 06/19/3008 19:22 GMT
Current job state: StageIn
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
Cleaning up any delegated credentials...Done.
<prompt>cognito %</prompt> <userinput>cat ~/stdout</userinput>
Hello World!
<prompt>cognito %</prompt> <userinput>ls ~/my_echo</userinput>
ls: /home/bacon/my_echo: No such file or directory
</screen>
</para>
  <para>You can get other examples of GRAM RSL files from <olink targetdoc="gram4User" targetptr="gram4-user-usagescenarios">GRAM usage scenarios</olink>.
</para>
</section>
</section>

<section id="q-vo"><title>VO-level services</title>
<section id="q-index"><title>Setting up an Index Service hierarchy</title>
<para>
Now that we have two machines, we can also setup some information services
to monitor them together.  Let's have cognito register its index service
into choate so we can have an aggregated view of the two machines, as
  described at <olink targetdoc="infoSamples" targetptr="wsmds-samples-DefaultIndexService">Building VOs</olink> in the MDS documentation:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>vim /usr/local/globus-<replaceable role="entity">version</replaceable>/etc/globus_wsrf_mds_index/hierarchy.xml </userinput>
<prompt>globus@cognito:~$</prompt> <userinput>grep upstream $GLOBUS_LOCATION/etc/globus_wsrf_mds_index/hierarchy.xml</userinput>
<![CDATA[
<!-- <upstream> elements specify remote index services that the local index
    Set an upstream entry for each VO index that you wish to participate in.
    <upstream>https://choate.mcs.anl.gov:8443/wsrf/services/DefaultIndexService</upstream>
]]>
root@cognito:~# /etc/init.d/globus-<replaceable role="entity">version</replaceable> restart
Stopping Globus container. PID: 18069
Container stopped
Starting Globus container. PID: 18405
</screen>
Now I can run some index service clients and check that the registration
worked:
<screen>
<prompt>cognito %</prompt> <userinput>setenv JAVA_HOME /usr/java/j2sdk1.4.2_10/</userinput>
<prompt>cognito %</prompt> <userinput>setenv ANT_HOME /usr/local/apache-ant-1.6.5/</userinput>
<prompt>cognito %</prompt> <userinput>setenv PATH $ANT_HOME/bin:$JAVA_HOME/bin:$PATH</userinput>
<prompt>cognito %</prompt> <userinput>host cognito</userinput>
cognito.mcs.anl.gov has address 140.221.8.109
<prompt>cognito %</prompt> <userinput>wsrf-query -s https://choate.mcs.anl.gov:8443/wsrf/services/DefaultIndexService '/*' | grep 140.221.8.109 | wc -l</userinput>
7
</screen>
So we've got seven entries in the remote index that reference our machine.  That means our upstream registration was processed successfully.  But what do those entries look like?  Here's an example:
<screen>
<![CDATA[
      <ns15:Address xmlns:ns15="http://schemas.xmlsoap.org/ws/2004/03/addressing">
https://140.221.8.109:8443/wsrf/services/ManagedJobFactoryService</ns15:Address>
]]>
</screen>
  It's hard to read, isn't it?  That's an entry in choate that points to the GRAM4 service running on cognito that we just setup.  But our life would be easier if we setup WebMDS to visualize the contents of the Index Service.  So let's do that next.
</para>
<note><para>
Notice that I hadn't setup my java variables yet, but the GRAM client above
worked just fine.  That's because it's written in C, even though it interacts
with the java container.  Language neutrality is one of the features of
webservices.
</para></note>
</section>

<section id="q-webmds"><title>Configuring WebMDS</title>
<para>
WebMDS has a dependency on the Tomcat container, so we'll install that now.  The recommended version is 5.0.28, which is available from the Apache Tomcat website.  We're following the standard install instructions from the <olink targetdoc="webmdsAdmin" targetptr="webmds-configuring">WebMDS Admin Guide</olink>.
<screen>
<prompt>root@cognito:/usr/local#</prompt> <userinput>tar xzf jakarta-tomcat-5.0.28.tar.gz </userinput>
<prompt>root@cognito:/usr/local#</prompt> <userinput>chown -R globus:globus jakarta-tomcat-5.0.28</userinput>
</screen>
Now the globus user can configure WebMDS:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>vim $GLOBUS_LOCATION/lib/webmds/conf/indexinfo</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>grep choate /usr/local/globus-<replaceable role="entity">version</replaceable>/lib/webmds/conf/indexinfo</userinput>
    &lt;value&gt;https://choate.mcs.anl.gov:8443/wsrf/services/DefaultIndexService&lt;/value&gt;
<prompt>globus@cognito:~$</prompt> <userinput>export CATALINA_HOME=/usr/local/jakarta-tomcat-5.0.28</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>$GLOBUS_LOCATION/lib/webmds/bin/webmds-create-context-file \</userinput>
          <userinput>$CATALINA_HOME/conf/Catalina/localhost</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>$CATALINA_HOME/bin/startup.sh</userinput>
Using CATALINA_BASE:   /usr/local/jakarta-tomcat-5.0.28
Using CATALINA_HOME:   /usr/local/jakarta-tomcat-5.0.28
Using CATALINA_TMPDIR: /usr/local/jakarta-tomcat-5.0.28/temp
Using JAVA_HOME:       /usr/java/j2sdk1.4.2_10/
</screen>
That started Tomcat on port 8080, so now I can browse to the /webmds directory on that port of my machine (http://cognito.mcs.anl.gov:8080/webmds/ but that's behind a firewall.  You can visit your own machine, though).  Now I can read the info stored in the index in human-readable format.  For instance, I can see this:
<screen>
RFT	140.221.8.31	0 active transfer resources, transferring 0 files.
26.06 KB transferred in 2 files since start of database.
</screen>
Those two RFT transfers were the one I ran by hand in the RFT section, then the RFT transfer that happened because of my GRAM job that used file staging.  I can also see some information about my GRAM services:
<screen>
GRAM	140.221.8.109	1 queues, submitting to 0 cluster(s) of 0 host(s).
</screen>
If I click for details, I get:
<screen>
ComputingElement:
Name: default
UniqueID: default
Info:
TotalCPUs: 1
</screen>
This works because the GRAM and RFT services are configured to register into the local service automatically.  When we edited the hierarchy.xml file to point to choate, all the information started to be cached centrally.
</para>
</section>
</section>
  <glossary role="auto" id="glossary-quickstart">
    <glossdiv><title>A</title>
      <glossentry>
        <glossterm>Irrelevant</glossterm>
        <glossdef>
          <para>If you can see this, the document was processed incorrectly. Use the
            <parameter>glossary.collection</parameter> parameter.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
  </glossary>
</article>

