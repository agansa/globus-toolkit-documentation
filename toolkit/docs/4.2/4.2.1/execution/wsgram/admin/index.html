<?php
include_once( "http://www-unix.globus.org/toolkit/docs/development/4.0-drafts/draft.inc" );
?>

<h1>GT 4.0 WS GRAM : System Administrator's Guide</h1>
<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li> <a href="#installing">Building and Installing</a></li>
  <li><a href="#configuring">Configuring</a></li>
  <li><a href="#testing">Testing</a></li>
  <li><a href="#troubleshooting">Troubleshooting</a></li>
</ul>
<h2><a name="introduction"></a>Introduction</h2>
<p>This document describes the installation and deployment of WS_GRAM including
  administrator-selected features, configuration options, and additional host
  settings necessary for WS_GRAM operation. Readers should be familiar with the <a href="../WS_GRAM_Key_Concepts.html">Key
  Concepts</a> and <a href="../WS_GRAM_Approach.html">Implementation Approach</a> for
  WS_GRAM to understand the motivation for and interaction of the various deployed
  components.</p>
<p>For basic instructions on installing GT 3.9.3, see the <a href="../../../admin/">Installation
    Guide</a>. </p>
<h2><a name="installing"></a>Building and Installing</h2>
<h3>Local Prerequisites</h3>
<p>WS_GRAM requires the following:</p>
<ul>
  <li><a href="#hostcredentials">Host credentials</a></li>
  <li><a href="#serviceaccount">GRAM service account </a></li>
  <li><a href="#sudo">Functioning sudo</a></li>
  <li><a href="#localscheduler">Local scheduler </a></li>
</ul>
<h4><a name="hostcredentials"></a>Host credentials</h4>
<p> In order to use WS_GRAM, the services running in the WSRF hosting environment
  require access to an appropriate host certificate.</p>
<h4><a name="serviceaccount"></a>GRAM service account</h4>
<p> WS_GRAM requires a dedicated local account within which the WSRF hosting
  environment and GRAM services will execute. This account will often be a <code>globus</code> account
  used for all local services, but may also be specialized to only host WS_GRAM.
  User jobs will run in separate accounts as specified in the <code>grid-mapfile</code> or
  associated authorization policy configuration of the host. </p>

<h4><a name="sudo"></a>Functioning sudo</h4>
<p> WS_GRAM requires that the <code>sudo</code> command is installed and functioning
  on the service host where WS_GRAM software will execute. </p>
<p> Authorization rules will need to be added to the <code>sudoers</code> file
  to allow the WS_GRAM service account to execute (without a password) local
  scheduler adapters in the accounts of authorized GRAM users. This topic is
  covered in detail in the Software Setup section. </p>
<h4><a name="localscheduler"></a>Local scheduler</h4>
<p> WS_GRAM depends on a local mechanism for starting and controlling jobs. If
  the fork-based WS_GRAM mode is to be used, no special software is required.
  For batch scheduling mechanisms, the local scheduler must be installed and
  configured for local job submission prior to deploying and operating WS_GRAM.
  The supported batch schedulers in the GT 3.9.3 release are: PBS, Condor, LSF</p>
<p> RFT prerequisites include PostgreSQL to be installed and configured. The
  instructions are <a href="../../../data/rft/admin/index.html">here</a> GRAM
  depends on RFT for file staging and cleanup. File staging from client host
  to compute host and visa versa. Jobs requesting these function will fail Without
  RFT properly setup. </p>
<h3><a name="fullinstall"></a>Full GT4 Installation including WS_GRAM</h3>
<ol>
  <li>Download and expand the full GT source tarball</li>
  <li>Build source</li>
  <pre>
        % wget &lt;GT tarball location&gt;/gt3.9.3-wsrf-source-installer.tar.gz
        % cd gt3.9.3-wsrf-source-installer
        % install-wsrf &lt;install directory&gt;
</pre>
  <li>Done! You have a full Globus Toolkit install including WS_GRAM - with the
    default configuration. </li>
</ol>
<h2><a name="configuring"></a>Configuring </h2>
<p>Information on configuration settings and environment variables can be found
  in the <a href="../WS_GRAM_Public_Interfaces.html">public interface guide</a>.</p>

<h3>Setting up service credentials</h3>
  In a default build and install of the Globus Toolkit, the local account is configured to use host credentials at /etc/grid-service/containercert.pem and containerkey.pem.  If you already have host certs, then you can just copy them to the new name and set ownership.

<pre>
	% cd /etc/grid-security
	% cp hostcert.pem containercert.pem
	% cp hostkey.pem containerkey.pem
	% chown globus.globus container*.pem
</pre>

(replace globus.globus with the user and group the container is
installed as)

<br>
You should now have something like:

<pre>
/etc/grid-security$ ls -l *.pem
-rw-r--r--  1 globus globus 1785 Oct 14 14:47 containercert.pem
-r--------  1 globus globus  887 Oct 14 14:47 containerkey.pem
-rw-r--r--  1 root   root   1785 Oct 14 14:42 hostcert.pem
-r--------  1 root   root    887 Sep 29 09:59 hostkey.pem
</pre>

The result is a copy of the host credentials which are accessible by the
container.

<p>
  If this is not an option, then you can configure an alternate location to point to host credentials -or- configure to use just a user proxy (personal mode).

<h3>Enabling Local Scheduler Adapter</h3>
<p>The batch scheduler interface implementations included in the release tarball
  are: PBS, Condor and LSF. To install one of the batch scheduler adapters, follow
  these steps:</p>
<pre>  % cd gt3.9.3-wsrf-source-installer
	% cd schedulers
	% ls
</pre>
<p>This gives you the following output:</p>
<pre>
gt4-gram-condor-3.9-src_bundle.tar.gz
gt4-gram-lsf-3.9-src_bundle.tar.gz
gt4-gram-pbs-3.9-src_bundle.tar.gz
</pre>
<p>Using PBS as the example, make sure the batch scheduler commands are in your
  path (qsub, qstat, pbsnodes). Then to build and install the PBS bundle type
  these commands:</p>
<pre>
	% gpt-build gt4-gram-pbs-3.9-src_bundle.tar.gz gcc32dbg
	% gpt-postinstall
</pre>
<p>Last thing is to define the <a href="../WS_GRAM_Public_Interfaces.html#filesysmap">GRAM
    and GridFTP file system mapping</a> for PBS.</p>
<p>Done! You have added the PBS scheduler adapters to your GT installation.</p>
<h3>Configuring sudo</h3>
<p>When the credentials of the service account and the job submitter are different
  (multi user mode), then GRAM will prepend a call to sudo to the local adapter
  callout command. If sudo is not configured properly, the command and thus job
  will fail.</p>
<p>As <b>root</b>, here are the two lines to add to the /etc/sudoers file for
  each GLOBUS_LOCATION installation, where /opt/globus/GT393 should be replaced
  with the GLOBUS LOCATION for your installation:</p>
<pre># Globus GRAM entries
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT393/libexec/globus-gridmap-and-execute 
           /opt/globus/GT393/libexec/globus-job-manager-script.pl *
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT393/libexec/globus-gridmap-and-execute 
           /opt/globus/GT393/libexec/globus-globus-gram-local-proxy-tool *
      </pre>
<h3>Extra steps for non-default installation</h3>

<h4>non-default service credentials</h4>

<h5>alternative location for host credentials</h5>
<p>If setting up host credentials in the default location of /etc/grid-security/containercert.pem and containerkey.pem is not an option for you, then you can configure an alternate location to point to host credentials.
</p>
<p>Security descriptor configuration details are <a href="../../../security/authzframe/security_descriptor.html#descFile">here</a>, but the quick change is to edit this file <tt>$GLOBUS_LOCATION/etc/globus_wsrf_core/global_security_descriptor.xml</tt>.  Change the cert and key paths to point to host credentials that the service account owns.</p>

<h5>User proxy</h5>
  To run the container using just a user proxy, simply comment out the ContainerSecDesc parameter in the this file <tt>$GLOBUS_LOCATION/etc/globus_wsrf_core/server-config.wsdd</tt> like so:
<pre>
    &lt;!--
        &lt;parameter 
            name="containerSecDesc" 
            value="etc/globus_wsrf_core/global_security_descriptor.xml"/&gt;
     --&gt;
      </pre>
<p>Running in personal mode (user proxy), another GRAM configuration setting
  is required. GRAM will authorize the RFT service when performing staging functions,
  it needs to know the subject DN for verification. Here are the steps:</p>
<pre>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-subject=
         "/DC=org/DC=doegrids/OU=People/CN=Stuart Martin 564720"
      </pre>
<p>You can get your subject DN by running this command:</p>
<pre>
	% grid-cert-info -subject
</pre>

<h4>non-default GridFTP server </h4>
<p>By default, the GridFTP server is assumed to run as root on localhost:2811.  If this is not true for your site then change it by running this command with the proper GridFTP URL values:</p>

<pre>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --gridftp-server=gsiftp://gridftp.host.org:1234"
      </pre>
<p> Also, the GridFTP host and/or port must be updated by editing the <a href="../WS_GRAM_Public_Interfaces.html#filesysmap">GRAM
    and GridFTP file system mapping</a> config file <code>$GLOBUS_LOCATION/etc/gram-service/globus_gram_fs_map_config.xml</code>. </p>
<h4>non-default container port</h4>
<p>By default, the globus services will assume 8080 is the port the Globus container
  is using. However the container can be run under a non-standard port, for example:</p>
<pre>
	% globus-start-container -p 4321
      </pre>
<p>When doing this, GRAM needs to be told the port to use to contact the RFT
  service, like so:</p>
<pre>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-port="4321"
      </pre>
<h2><a name="testing"></a>Testing</h2>
<p>See the WS GRAM <a href="../user/commandline_java_managed_globus_run.html#interactivemode">users
    guide</a> for submitting a test job.</p>
<h2><a name="troubleshooting"></a>Troubleshooting</h2>
<p>&nbsp;</p>
