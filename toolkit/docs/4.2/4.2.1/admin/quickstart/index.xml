<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.4//EN"
"http://www.oasis-open.org/docbook/xml/4.4/docbookx.dtd">

<article id="quickstart" xreflabel="GT Quickstart">
<title>GT <replaceable role="entity">shortversion</replaceable> Quickstart</title>
  <titleabbrev>Quickstart</titleabbrev>

<articleinfo id="q-intro"><abstract><title>Introduction</title>
<para>
This is a quickstart that shows a full installation of the Toolkit
on two Debian 3.1 machines.  It shows the installation of prereqs, 
installation of the toolkit, creation of <glossterm baseform="certificate">certificates</glossterm>, and configuration
of services.  It is designed to supplement the main admin guide.
</para></abstract>
</articleinfo>

<section id="q-first"><title>Setting up the first machine</title>

<section id="q-prereq"><title>Pre-requisites</title>

<para>I will be installing all of the toolkit from source, so
I'm going to double-check my system for pre-requisites.  The full list
of prereqs is available at 
  <olink targetdoc="gtadmin" targetptr="gtadmin-prereq">Software Prerequisites</olink> in the GT <replaceable role="entity">shortversion</replaceable> Admin Guide.
</para>


<para>First I'll check for security libraries:
<screen>
<prompt>elephant %</prompt> <userinput>openssl version</userinput>
OpenSSL 0.9.7e 25 Oct 2004

<prompt>elephant %</prompt> <userinput>dpkg --list | grep zlib</userinput>
ii  zlib-bin       1.2.2-4.sarge. compression library - sample programs
ii  zlib1g         1.2.2-4.sarge. compression library - runtime
ii  zlib1g-dev     1.2.2-4.sarge. compression library - development
</screen>
openssl 0.9.7 (or newer, 0.9.8 is okay) and the zlib development libraries are required.
</para>
<note>
<para>The package names for zlib may vary for non-Debian systems.  The RPM name
we would look for is <filename>zlib-devel</filename>.</para>
</note>

<para>I also have j2sdk1.5-sun installed under /usr/lib/j2sdk1.5-sun from the sun-j2sdk1.5
dpkg:
<screen>
<prompt>elephant % </prompt><userinput>dpkg -S /usr/lib/j2sdk1.5-sun</userinput>
sun-j2sdk1.5: /usr/lib/j2sdk1.5-sun
</screen>
<note><para>Note that GT4.2 requires Java 5 or higher.  Java 1.4.2 is no longer supported.</para></note>
</para>

<para>I also have ant installed:
<screen>
<prompt>elephant % </prompt><userinput>ls /home/dsl/javapkgs/apache-ant-1.6.5/</userinput>
bin   INSTALL  LICENSE	    LICENSE.xerces  TODO
docs  KEYS     LICENSE.dom  NOTICE	    welcome.html
etc   lib      LICENSE.sax  README	    WHATSNEW
</screen>
</para>
<note><para>
Most RedHat and Fedora Core boxes already ship with ant, but it is configured to use gcj.
We don't want to use gcj!  To fix this, look for an /etc/ant.conf file.  If you have one,
rename it to /etc/ant.conf.orig for the duration of this quickstart.
</para></note>

<para>My system already has C/C++ compilers:
<screen>
<prompt>elephant % </prompt><userinput>which gcc</userinput>
/usr/bin/gcc
<prompt>elephant % </prompt><userinput>which g++</userinput>
/usr/bin/g++
</screen>
</para>

<para>GNU versions of tar/make/sed:
<screen>
<prompt>elephant % </prompt><userinput>tar --version</userinput>
tar (GNU tar) 1.14
Copyright (C) 2004 Free Software Foundation, Inc.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute it under the terms of the GNU General Public License;
see the file named COPYING for details.
Written by John Gilmore and Jay Fenlason.
<prompt>elephant % </prompt><userinput>sed --version</userinput>
GNU sed version 4.1.2
Copyright (C) 2003 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE,
to the extent permitted by law.
<prompt>elephant % </prompt><userinput>make --version</userinput>
GNU Make 3.80
Copyright (C) 2002  Free Software Foundation, Inc.
This is free software; see the source for copying conditions.
There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A
PARTICULAR PURPOSE.
</screen>
</para>

<para>Finally, I have sudo and XML::Parser for GRAM:
<screen>
<prompt>elephant % </prompt><userinput>sudo -V</userinput>
Sudo version 1.6.8p7
<prompt>elephant % </prompt><userinput>locate XML/Parser.pm</userinput>
/usr/lib/perl5/XML/Parser.pm
</screen>
</para>
</section>

<section id="q-toolkit"><title>Building the Toolkit</title>
<para>
That completes the list of build prereqs, so now I will download the installer and build it.  The long version of these instructions is at <olink targetdoc="gtadmin" targetptr="gtadmin-install"/>.  First I created a globus user, and I will start the installation from that.  First I will setup my ANT_HOME and JAVA_HOME:
<screen>
<prompt>globus@elephant:~$ </prompt><userinput>export ANT_HOME=/home/dsl/javapkgs/apache-ant-1.6.5/</userinput>
<prompt>globus@elephant:~$ </prompt><userinput>export JAVA_HOME=/usr/lib/j2sdk1.5-sun</userinput>
<prompt>globus@elephant:~$ </prompt><userinput>export PATH=$ANT_HOME/bin:$JAVA_HOME/bin:$PATH</userinput>
<prompt>globus@elephant:~$</prompt> <userinput>tar xzf gt<replaceable role="entity">version</replaceable>-all-source-installer.tar.gz</userinput>
<prompt>globus@elephant:~$</prompt> <userinput>cd gt<replaceable role="entity">version</replaceable>-all-source-installer</userinput>
<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>./configure --prefix=/sandbox/globus-<replaceable role="entity">version</replaceable>/</userinput>
checking build system type... i686-pc-linux-gnu
checking for javac... /usr/lib/j2sdk1.5-sun/bin/javac
checking for ant... /home/dsl/javapkgs/apache-ant-1.6.5//bin/ant
configure: creating ./config.status
config.status: creating Makefile
</screen>
</para>

<note><para>
The machine I am installing on doesn't have access to a scheduler.  If it did, I would have specified one of the wsgram scheduler options, 
  like <option>--enable-wsgram-condor</option>, <option>--enable-wsgram-lsf</option>, or <option>--enable-wsgram-pbs</option>.
</para></note>
<note><para>
I could have used the binary installer for this example, because Debian ia32 binaries are available.  
To make the quickstart more general, I decided to use source instead.
</para></note>

<para>Now it's time to build the toolkit:
<screen>
<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>make | tee installer.log</userinput>
cd gpt-3.2autotools2004 &amp;&amp; OBJECT_MODE=32 ./build_gpt
build_gpt ====&gt; installing GPT into /sandbox/globus/globus-<replaceable role="entity">version</replaceable>/
...
Time for a coffee break here, the build will take over an hour, possibly
longer depending on how fast your machine is
...
Your build completed successfully.  Please run make install.

<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> <userinput>make install</userinput>
/sandbox/globus/globus-<replaceable role="entity">version</replaceable>//sbin/gpt-postinstall
...
..Done

<prompt>globus@elephant:~/gt<replaceable role="entity">version</replaceable>-all-source-installer$</prompt> 
</screen>
</para>
</section>

<section id="q-security"><title>Setting up security on your first machine</title>
<para>
All of the work we're going to do now requires that we be authenticated and authorized.  We
use certificates for this purpose.  The Distinguished Name (DN) of a certificate will serve
as our authenticated identity.  That identity will then be authorized.  In this simple tutorial,
the authorization will happen in a file lookup.
</para>
<para>
We will need identites for both the services and users. For the services, we will use an identity
that is equal to their hostname.  For the users, we'll use their full name.  To create the certificates, 
we're going to use the SimpleCA that is distributed with the toolkit.  
Here's how we set it up, based on the instructions at
<olink targetdoc="gtadmin" targetptr="gtadmin-simpleca">SimpleCA Admin</olink>:
<screen>
<prompt>globus@elephant:~$</prompt> <userinput>export GLOBUS_LOCATION=/sandbox/globus/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>globus@elephant:~$</prompt> <userinput>source $GLOBUS_LOCATION/etc/globus-user-env.sh</userinput>
<prompt>globus@elephant:~$</prompt> <userinput>perl gt-server-ca.pl -y</userinput>
Setting up /sandbox/globus/globus-4.2.0/
Please enter a password of at least four characters for the CA: 
Confirm password:
Creating a new simpleCA, logging to gt-server-ca.log...
Running setup-gsi...
Your CA hash is: 1bcdfe89
It is located at /sandbox/globus/globus-4.2.0//share/certificates/1bcdfe89.0
Your host DN is /O=Grid/OU=GlobusTest/OU=simpleCA-elephant.mcs.anl.gov/CN=host/elephant.mcs.anl.gov
The hostcert is located at /sandbox/globus/globus-4.2.0//etc/hostcert.pem

<prompt>globus@elephant:~$ </prompt>
</screen>
<note><para>This will fail if /tmp is mounted noexec.  If you get a failure, you might try setting
GLOBUS_SH_TMP=`pwd` and trying again.
</para>
</note>
</para>

<para>
Here's what has happened:
<screen>
<prompt>globus@elephant:~$</prompt> <userinput>ls ~/.globus/</userinput>
simpleCA
<prompt>globus@elephant:~$</prompt> <userinput>ls ~/.globus/simpleCA/</userinput>
cacert.pem  globus_simple_ca_1bcdfe89_setup-0.18.tar.gz  newcerts
certs       grid-ca-ssl.conf                             private
crl         index.txt                                    serial
</screen>
That's the directory where my simpleCA has been created.  
  These files are all explained in the 
  <olink targetdoc="prewsaaAdmin">Security Admin Guide</olink>.
</para>

<para>
Our last step is to copy that signed certificate into <filename class="directory">/etc</filename>:
<screen>
<prompt>root@elephant:~#</prompt> <userinput>cp ~globus/hostsigned.pem /etc/grid-security/hostcert.pem </userinput>
</screen>
</para>

<para>
We'll make the containercerts owned by globus:
<screen>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>chown globus:globus container*.pem</userinput>
<prompt>root@elephant:/etc/grid-security#</prompt> <userinput>ls -l *.pem</userinput>
-rw-r--r--  1 globus globus 2724 2008-06-16 14:26 etc/containercert.pem
-r--------  1 globus globus  887 2008-06-16 14:26 etc/containerkey.pem
-rw-r--r--  1 root root     2724 2008-06-16 14:26 etc/hostcert.pem
-rw-r--r--  1 root root     1404 2008-06-16 14:26 etc/hostcert_request.pem
-r--------  1 root root      887 2008-06-16 14:26 etc/hostkey.pem
</screen>
</para>
</section>

<section><title>Creating a MyProxy server</title>
<para>
We are going to create a MyProxy server on elephant, following the instructions at 
<olink targetdoc="myproxyAdmin" targetptr="myproxy-configuring">configuring MyProxy</olink>.  This will be used to
store our user's certificates.  Recall that so far we have made a host certificate, but we don't have any certificates for
end users yet.
<screen>
<prompt>root@elephant:~#</prompt> <userinput>export GLOBUS_LOCATION=/usr/local/globus-<replaceable role="entity">version</replaceable>/</userinput>
<prompt>root@elephant:~#</prompt> <userinput>cp $GLOBUS_LOCATION/etc/myproxy-server.config /etc</userinput>
<prompt>root@elephant:~#</prompt> <userinput>vim /etc/myproxy-server.config </userinput>
<prompt>root@elephant:~#</prompt> <userinput>diff /etc/myproxy-server.config $GLOBUS_LOCATION/etc/myproxy-server.config</userinput>
15,21c15,21
&lt; accepted_credentials  "*"
&lt; authorized_retrievers "*"
&lt; default_retrievers    "*"
&lt; authorized_renewers   "*"
&lt; default_renewers      "none"
&lt; authorized_key_retrievers "*"
&lt; default_key_retrievers "none"
---
&gt; #accepted_credentials  "*"
&gt; #authorized_retrievers "*"
&gt; #default_retrievers    "*"
&gt; #authorized_renewers   "*"
&gt; #default_renewers      "none"
&gt; #authorized_key_retrievers "*"
&gt; #default_key_retrievers "none"
<prompt>root@elephant:~#</prompt> <userinput>cat $GLOBUS_LOCATION/share/myproxy/etc.services.modifications >> /etc/services </userinput>
<prompt>root@elephant:~#</prompt> <userinput>tail /etc/services </userinput>
binkp           24554/tcp                       # binkp fidonet protocol
asp             27374/tcp                       # Address Search Protocol
asp             27374/udp
dircproxy       57000/tcp                       # Detachable IRC Proxy
tfido           60177/tcp                       # fidonet EMSI over telnet
fido            60179/tcp                       # fidonet EMSI over TCP
# Local services
gsiftp          2811/tcp
myproxy-server  7512/tcp                        # Myproxy server
<prompt>root@elephant:~#</prompt> <userinput>cp $GLOBUS_LOCATION/share/myproxy/etc.xinetd.myproxy /etc/xinetd.d/myproxy</userinput>
<prompt>root@elephant:~#</prompt> <userinput>vim /etc/xinetd.d/myproxy </userinput>
<prompt>root@elephant:~#</prompt> <userinput>cat /etc/xinetd.d/myproxy </userinput>
service myproxy-server
{
  socket_type  = stream
  protocol     = tcp
  wait         = no
  user         = root
  server       = /usr/local/globus-<replaceable role="entity">version</replaceable>/sbin/myproxy-server
  env          = GLOBUS_LOCATION=/usr/local/globus-<replaceable role="entity">version</replaceable> LD_LIBRARY_PATH=/usr/local/globus-<replaceable role="entity">version</replaceable>/lib <co id="myproxy_ld-co" linkends="myproxy_ld"/>
  disable      = no
}
<prompt>root@elephant:~#</prompt> <userinput>/etc/init.d/xinetd reload</userinput>
Reloading internet superserver configuration: xinetd.
<prompt>root@elephant:~#</prompt> <userinput>netstat -an | grep 7512</userinput>
tcp        0      0 0.0.0.0:7512            0.0.0.0:*               LISTEN     
</screen>
<calloutlist>
   <callout arearefs="myproxy_ld-co" id="myproxy_ld" >
    <simpara>Your system may require a different environment variable than LD_LIBRARY_PATH if you're using MacOS X or IRIX</simpara>
   </callout>
</calloutlist>
</para>

<para>
Now that myproxy is setup, we'll get a usercert for bacon.  The globus user will add a new credential into myproxy.
I have to specify a full name
and a login name.  I'll be using "Charles Bacon" and "bacon" for my user.  I have to supply two different passwords.  The
first password is going to be the bacon user's password.  The second password has to be my SimpleCA password from when
I ran gt-server-ca.pl.
<screen>
<prompt>globus@elephant:</prompt> <userinput>myproxy-admin-adduser -c "Charles Bacon" -l bacon</userinput>
iA certificate request and private key is being created.
You will be asked to enter a PEM pass phrase.
This pass phrase is akin to your account password, 
and is used to protect your key file.
If you forget your pass phrase, you will need to
obtain a new certificate.

Generating a 1024 bit RSA private key
......................++++++
...++++++
writing new private key to '/tmp/myproxy_adduser_HUTit8/myproxy_adduser_key.pem'
Enter PEM pass phrase: <userinput>bacon's new password</userinput>
Verifying - Enter PEM pass phrase: <userinput>bacon's new password</userinput>
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Level 0 Organization [Grid]:Level 0 Organizational Unit [GlobusTest]:Level 1 Organizational Unit [simpleCA-elephant.mcs.anl.gov]:Level 2 Organizational Unit [mcs.anl.gov]:Name (e.g., John M. Smith) []:

A private key and a certificate request has been generated with the subject:

/O=Grid/OU=GlobusTest/OU=simpleCA-elephant.mcs.anl.gov/OU=mcs.anl.gov/CN=Charles Bacon

If the CN=Charles Bacon is not appropriate, rerun this
script with the -force -cn "Common Name" options.

Your private key is stored in /tmp/myproxy_adduser_HUTit8/myproxy_adduser_key.pem
Your request is stored in /tmp/myproxy_adduser_HUTit8/myproxy_adduser_cert_request.pem

Please e-mail the request to the Globus Simple CA 
You may use a command similar to the following:

  cat /tmp/myproxy_adduser_HUTit8/myproxy_adduser_cert_request.pem | mail 

Only use the above if this machine can send AND receive e-mail. if not, please
mail using some other method.

Your certificate will be mailed to you within two working days.
If you receive no response, contact Globus Simple CA at 

To sign the request
please enter the password for the CA key: <userinput>SimpleCA password</userinput>

The new signed certificate is at: /homes/globus/.globus/simpleCA//newcerts/05.pem

using storage directory /sandbox/globus/globus-4.2.0//var/myproxy
Credential stored successfully
</screen>

Our last act will be to create a grid-mapfile as root for authorization.  You can copy and paste the /O=Grid/OU=... 
subject name from the output above:
<screen>
<prompt>root@choate:/etc/grid-security#</prompt> <userinput>vim /etc/grid-security/grid-mapfile</userinput>
"/O=Grid/OU=GlobusTest/OU=simpleCA-choate.mcs.anl.gov/OU=mcs.anl.gov/CN=Charles Bacon" bacon
</screen>
</para>
<note><para>
The globus user doesn't need a user certificate!  It's a dummy account that
we're using to own the GLOBUS_LOCATION.  When it starts the container, it
will use the containercert.  Only real people need user certs.
</para></note>

</section>

<section id="q-gridftp"><title>Set up GridFTP</title>
<para>
Now that we have our host and user credentials in place, we can start a service.  This setup comes from the 
  <olink targetdoc="gridftpAdmin">GridFTP Admin Guide</olink>.
<screen>
  <prompt>root@choate:/etc/grid-security#</prompt> <userinput>vim /etc/xinetd.d/gridftp</userinput> <co id="q-xinetd-co" linkends="q-xinetd"/>
<prompt>root@choate:/etc/grid-security#</prompt> <userinput>cat /etc/xinetd.d/gridftp</userinput>
service gsiftp
{
instances               = 100
socket_type             = stream
wait                    = no
user                    = root
env                     += GLOBUS_LOCATION=/usr/local/globus-<replaceable role="entity">version</replaceable>
  env                     += LD_LIBRARY_PATH=/usr/local/globus-<replaceable role="entity">version</replaceable>/lib <co  id="q-ld_lib-co"  linkends="q-ld_lib" />

server                  = /usr/local/globus-<replaceable role="entity">version</replaceable>/sbin/globus-gridftp-server
server_args             = -i
log_on_success          += DURATION
nice                    = 10
disable                 = no
}
<prompt>root@choate:/etc/grid-security#</prompt> <userinput>vim /etc/services </userinput>
<prompt>root@choate:/etc/grid-security#</prompt> <userinput>tail /etc/services </userinput>
vboxd           20012/udp
binkp           24554/tcp                       # binkp fidonet protocol
asp             27374/tcp                       # Address Search Protocol
asp             27374/udp
dircproxy       57000/tcp                       # Detachable IRC Proxy
tfido           60177/tcp                       # fidonet EMSI over telnet
fido            60179/tcp                       # fidonet EMSI over TCP

# Local services
gsiftp          2811/tcp
<prompt>root@choate:/etc/grid-security#</prompt> <userinput>/etc/init.d/xinetd reload</userinput>
Reloading internet superserver configuration: xinetd.
<prompt>root@choate:/etc/grid-security#</prompt> <userinput>netstat -an | grep 2811</userinput>
tcp        0      0 0.0.0.0:2811            0.0.0.0:*               LISTEN     
</screen>
<calloutlist>
  <callout arearefs="q-xinetd-co"  id="q-xinetd" >
    <para>I already had xinetd installed:
    <screen>
bacon@choate:~$ dpkg --list xinetd
Desired=Unknown/Install/Remove/Purge/Hold
| Status=Not/Installed/Config-files/Unpacked/Failed-config/Half-installed
|/ Err?=(none)/Hold/Reinst-required/X=both-problems (Status,Err: uppercase=bad)
||/ Name           Version        Description
+++-==============-==============-============================================
      ii  xinetd         2.3.13-3       replacement for inetd with many enhancements</screen>
      You can use inetd instead, see "Configuring the GridFTP server to run under xinetd/inetd" in <olink targetdoc="gridftpAdmin"/> for details.  
      For now, though, you might want to apt-get install xinetd.</para>
  </callout>
  <callout arearefs="q-ld_lib-co"  id="q-ld_lib" >
    <simpara>On MacOS X, this would be DYLD_LIBRARY_PATH.  Check your system documentation if LD_LIBARARY_PATH doesn't work on your system.</simpara>
  </callout>
</calloutlist>
   
</para>

<para>
Now the gridftp server is waiting for a request, so we'll run a client
and transfer a file:
<screen>
<prompt>bacon@elephant $</prompt> <userinput>myproxy-logon -s elephant</userinput>
Enter MyProxy pass phrase: <userinput>******</userinput>
A credential has been received for user bacon in /tmp/x509up_u1817.
<prompt>bacon@elephant $</prompt> <userinput>globus-url-copy gsiftp://choate.mcs.anl.gov/etc/group file:///tmp/bacon.test.copy</userinput>
<prompt>bacon@elephant $</prompt> <userinput>diff /tmp/bacon.test.copy /etc/group</userinput>
<prompt>bacon@elephant $</prompt> <userinput></userinput>
</screen>
</para>

<para>Okay, so the GridFTP server works.  If you had trouble, check the
  security troubleshooting section in the <olink targetdoc="prewsaaAdmin">Security Admin Guide</olink>.  Now we can move on to starting the webservices container.
</para>
</section>

<section id="q-container"><title>Starting the webservices container</title>

<para>Now we'll setup an /etc/init.d entry for the webservices container.  You can find more details about the container at 
  <olink targetdoc="javawscoreAdmin" />.
<screen>
<prompt>root@choate:~#</prompt> <userinput>cp $GLOBUS_LOCATION/etc/init.d/globus-ws-java-container /etc/init.d</userinput>
<prompt>root@choate:~#</prompt> <userinput>/etc/init.d/globus-ws-java-container start</userinput>
Starting Globus container. PID: 29985
</screen> 
</para>

<para>At this point, we can use one of the sample clients/services to interact with the container:
<screen>
<prompt>bacon@elephant $</prompt> <userinput>globus-check-remote-environment -s https://localhost:8443</userinput>

### Remote Endpoint Version Information ###
Axis Version on remote endpoint https://localhost:8443:
Apache Axis version: 1.4
Built on Mar 01, 2007 (10:42:15 CST)

Java WS Core Version on remote endpoint https://localhost:8443:
4.2.0

</screen>
That is the expected output, so it looks like the container is up and running.  Next we'll configure a database for RFT to get rid of that pesky warning, and so we can 
  reliably transfer files using GridFTP!
</para>
</section>

<section id="q-rft"><title>Configuring RFT</title>
<para>
  Following the instructions at <olink targetdoc="rftAdmin" />, we'll first configure the system to allow TCP/IP connections to postgres, as well as adding a trust 
  entry for our current host:
<screen>
<prompt>root@choate:~#</prompt> <userinput>vim /var/lib/postgres/postmaster.conf </userinput>
<prompt>root@choate:~#</prompt> <userinput>grep POSTMASTER /var/lib/postgres/postmaster.conf </userinput>
POSTMASTER_OPTIONS="-i"
<prompt>root@choate:~#</prompt> <userinput>vim /var/lib/postgres/data/pg_hba.conf </userinput>
<prompt>root@choate:~#</prompt> <userinput>grep rftDatabase /etc/postgresql/pg_hba.conf </userinput>
host rftDatabase "globus" "140.221.8.31" 255.255.255.255 md5
<prompt>root@choate:~#</prompt> <userinput>/etc/init.d/postgresql restart</userinput>
Stopping PostgreSQL database server: postmaster.
Starting PostgreSQL database server: postmaster.
<prompt>root@choate:~#</prompt> <userinput>su postgres -c "createuser -P globus"</userinput>
Enter password for new user: <userinput>*****</userinput>
Enter it again: <userinput>*****</userinput>
Shall the new user be allowed to create databases? (y/n) y
Shall the new user be allowed to create more new users? (y/n) n
CREATE USER
</screen>
</para>
<note><para>
This is one of the most system-dependent steps of this quickstart.  Your
pg_hba.conf and postmaster.conf files may be located in a different directory.  Please consult your vendor's notes for details.
</para></note>

<para>
Now the globus user can create the rftDatabase:
<screen>
<prompt>globus@choate:~$</prompt> <userinput>createdb rftDatabase</userinput>
CREATE DATABASE
<prompt>globus@choate:~$</prompt> <userinput>psql -d rftDatabase -f $GLOBUS_LOCATION/share/globus_wsrf_rft/rft_schema.sql</userinput>
psql:/usr/local/globus-<replaceable role="entity">version</replaceable>/share/globus_wsrf_rft/rft_schema.sql:6: NOTICE:
CREATE TABLE / PRIMARY KEY will create implicit index "requestid_pkey" for table "requestid"
CREATE TABLE
psql:/usr/local/globus-<replaceable role="entity">version</replaceable>/share/globus_wsrf_rft/rft_schema.sql:11: NOTICE: 
CREATE TABLE / PRIMARY KEY will create implicit index "transferid_pkey" for table "transferid"
CREATE TABLE
psql:/usr/local/globus-<replaceable role="entity">version</replaceable>/share/globus_wsrf_rft/rft_schema.sql:30: NOTICE: 
CREATE TABLE / PRIMARY KEY will create implicit index "request_pkey" for table "request"
CREATE TABLE
psql:/usr/local/globus-<replaceable role="entity">version</replaceable>/share/globus_wsrf_rft/rft_schema.sql:65: NOTICE: 
CREATE TABLE / PRIMARY KEY will create implicit index "transfer_pkey" for table "transfer"
CREATE TABLE
CREATE TABLE
CREATE TABLE
CREATE INDEX
<prompt>globus@choate:~$</prompt> <userinput>vim $GLOBUS_LOCATION/etc/globus_wsrf_rft/jndi-config.xml</userinput>
<prompt>globus@choate:~$</prompt> <userinput>grep -C 3 password $GLOBUS_LOCATION/etc/globus_wsrf_rft/jndi-config.xml </userinput>
            &lt;/parameter&gt;
            &lt;parameter&gt;
                &lt;name&gt;
                password
                &lt;/name&gt;
                &lt;value&gt;
                *****
</screen>
I have created the database, loaded the RFT schema, and changed the password in the jndi-config.xml file.
</para>

<para>
The database is setup, so we restart the container to load the new RFT
configuration:
<screen>
<prompt>root@choate:~#</prompt> <userinput>/etc/init.d/globus-<replaceable role="entity">version</replaceable> restart</userinput>
Stopping Globus container. PID: 29985
Starting Globus container. PID: 8620
<prompt>root@choate:~#</prompt> <userinput>head /usr/local/globus-<replaceable role="entity">version</replaceable>/var/container.log</userinput>
Starting SOAP server at: https://140.221.8.31:8443/wsrf/services/ 
With the following services:

[1]: https://140.221.8.31:8443/wsrf/services/TriggerFactoryService
[2]: https://140.221.8.31:8443/wsrf/services/DelegationTestService
[3]: https://140.221.8.31:8443/wsrf/services/SecureCounterService
[4]: https://140.221.8.31:8443/wsrf/services/IndexServiceEntry
[5]: https://140.221.8.31:8443/wsrf/services/DelegationService
[6]: https://140.221.8.31:8443/wsrf/services/InMemoryServiceGroupFactory
[7]: https://140.221.8.31:8443/wsrf/services/mds/test/execsource/IndexService
...
</screen>
Great, we got rid of the warning.  Now let's try an RFT transfer to make sure the service is really working:
<screen>
<prompt>choate %</prompt> <userinput>cp /usr/local/globus-<replaceable role="entity">version</replaceable>/share/globus_wsrf_rft_test/transfer.xfr /tmp/rft.xfr</userinput>
<prompt>choate %</prompt> <userinput>vim /tmp/rft.xfr </userinput>
<prompt>choate %</prompt> <userinput>cat /tmp/rft.xfr </userinput>
true
16000
16000
false
1
true
1
null
null
false
10
gsiftp://choate.mcs.anl.gov:2811/etc/group
gsiftp://choate.mcs.anl.gov:2811/tmp/rftTest_Done.tmp
<prompt>choate %</prompt> <userinput>rft -h choate.mcs.anl.gov -f /tmp/rft.xfr </userinput>
Number of transfers in this request: 1
Subscribed for overall status
Termination time to set: 60 minutes

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
0/1/0/0/0

 Overall status of transfer:
Finished/Active/Failed/Retrying/Pending
1/0/0/0/0
All Transfers are completed
<prompt>choate %</prompt> <userinput>diff /etc/group /tmp/rftTest_Done.tmp </userinput>
<prompt>choate %</prompt> 
</screen>
RFT did its job, starting up a reliable transfer and notifying us of the status and results.
</para>
</section>

  <section id="q-gram"><title>Setting up GRAM4</title>
<para>
Now that we have GridFTP and RFT working, we can setup GRAM for resource
management.  First we have to setup sudo so the globus user can start jobs
  as a different user.  For reference, you can see the <olink targetdoc="gram4Admin" />.
  <screen>
    <prompt>root@choate:~#</prompt> <userinput>visudo</userinput>
<prompt>root@choate:~#</prompt> <userinput>cat /etc/sudoers </userinput>
globus ALL=(bacon) NOPASSWD: /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-gridmap-and-execute
-g /etc/grid-security/grid-mapfile /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-job-manager-script.pl *
globus  ALL=(bacon) NOPASSWD: /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-gridmap-and-execute
-g /etc/grid-security/grid-mapfile /usr/local/globus-<replaceable role="entity">version</replaceable>/libexec/globus-gram-local-proxy-tool *
</screen>
Make sure they're all on one line.  I split them up in the HTML to keep the page width down.  With that addition, we can now run jobs:
<screen>
<prompt>choate %</prompt> <userinput>globusrun-ws -submit -c /bin/true</userinput>
Submitting job...Done.
Job ID: uuid:3304e3f2-55f2-11da-8b8f-00d0b7b7c0bc
Termination time: 11/16/2005 16:09 GMT
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
<prompt>choate %</prompt> <userinput>echo $?</userinput>
0
<prompt>choate %</prompt> <userinput>globusrun-ws -submit -c /bin/false</userinput>
Submitting job...Done.
Job ID: uuid:456b7c9a-55f2-11da-9b0d-00d0b7b7c0bc
Termination time: 11/16/2005 16:09 GMT
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
<prompt>choate %</prompt> <userinput>echo $?</userinput>
1
</screen>
Success.  Now we've got a working GRAM installation.
</para>
</section>
</section>

<section id="q-second"><title>Setting up your second machine</title>
<section id="q-prereq2"><title>Setting up your second machine: Prereqs</title>
<para>
Alas, it's not much of a grid with just one machine.  So let's start up
on another machine and add it to this little test grid.  For a change of
pace, I'm going to use the binary installer on this machine.  First, though,
let's get some prereqs out of the way:
<screen>
<prompt>root@cognito:~#</prompt> <userinput>adduser globus</userinput>
<prompt>root@cognito:~#</prompt> <userinput>mkdir /usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>root@cognito:~#</prompt> <userinput>chown globus:globus /usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>root@cognito:/usr/java#</prompt> <userinput>./j2sdk-1_4_2_10-linux-i586.bin </userinput>
<prompt>root@cognito:/usr/local#</prompt> <userinput>tar xzf apache-ant-1.6.5-bin.tar.gz </userinput>
</screen>
Then, as user globus:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>tar xzf gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer.tar.gz</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>export JAVA_HOME=/usr/java/j2sdk1.4.2_10/</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>export ANT_HOME=/usr/local/apache-ant-1.6.5/</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>export PATH=$ANT_HOME/bin:$JAVA_HOME/bin:$PATH</userinput>
</screen>
</para>
<note><para>
You might notice that I didn't install Postgres on this machine.  That's
because my grid can actually share the services of the RFT located on my
first machine.  Even if I weren't planning on that, I could add this new
machine to the pg_hba.conf on the first machine and re-use the existing
DB server.
</para></note>

</section>

<section id="q-toolkit2"><title>Setting up your second machine: Installation</title>
<para>
Now we can install from binaries:
<screen>

<prompt>globus@cognito:~/gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer$</prompt> <userinput>./configure \
   --prefix=/usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
checking for javac... /usr/java/j2sdk1.4.2_10//bin/javac
checking for ant... /usr/local/apache-ant-1.6.5//bin/ant
configure: creating ./config.status
config.status: creating Makefile
<prompt>globus@cognito:~/gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer$</prompt> <userinput>make</userinput>
cd gpt-3.2autotools2004 &amp;&amp; OBJECT_MODE=32 ./build_gpt
...
Binaries are much faster!  This is done in less than 10 minutes.
...
tar -C /usr/local/globus-<replaceable role="entity">version</replaceable> -xzf binary-trees/globus_wsrf_rft_test-*/*.tar.gz
tar -C /usr/local/globus-<replaceable role="entity">version</replaceable> -xzf binary-trees/globus_rendezvous-*/*.tar.gz
echo "Your build completed successfully.  Please run make install."
Your build completed successfully.  Please run make install.
<prompt>globus@cognito:~/gt<replaceable role="entity">version</replaceable>-ia32_debian_3.1-binary-installer$</prompt> <userinput>make install</userinput>
ln -s /usr/local/globus-<replaceable role="entity">version</replaceable>/etc/gpt/packages /usr/local/globus-<replaceable role="entity">version</replaceable>/etc/globus_packages
...
config.status: creating fork.pm
..Done
</screen>
</para>
</section>

<section id="q-security2"><title>Setting up your second machine: Security</title>
<para>Now let's get security setup on the second machine.  We're going to just add trust for the original simpleCA to this new machine, there's no need to create a new one.  All we need to do is copy the $GLOBUS_LOCATION/share/certificates from our
first machine to our second:
<screen>
<prompt>globus@crunch:~$</prompt> <userinput>export GLOBUS_LOCATION=/usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>globus@crunch:~$</prompt> <userinput>scp -r elephant:/sandbox/globus/globus-4.2.0/share/certificates $GLOBUS_LOCATION/share</userinput>
</screen>

<screen>
<prompt>globus@choate:/tmp$</prompt> <userinput>grid-ca-sign -in in.pem -out out.pem</userinput>

To sign the request
please enter the password for the CA key:

The new signed certificate is at: /home/globus/.globus/simpleCA//newcerts/03.pem
<prompt>globus@choate:/tmp$</prompt> <userinput> cat /tmp/out.pem | mail root@cognito</userinput>
</screen>
Root checks his email, then saves the signed cert:
<screen>
<prompt>root@cognito:~#</prompt> <userinput>cp out.pem /etc/grid-security/hostcert.pem </userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>cp hostcert.pem containercert.pem</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>cp hostkey.pem containerkey.pem</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>chown globus:globus container*.pem</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>ls -l *.pem</userinput>
-rw-r--r--  1 globus globus 2711 2005-11-15 11:14 containercert.pem
-r--------  1 globus globus  887 2005-11-15 11:15 containerkey.pem
-rw-r--r--  1 root   root   2711 2005-11-15 11:14 hostcert.pem
-rw-r--r--  1 root   root   1405 2005-11-15 11:09 hostcert_request.pem
-r--------  1 root   root    887 2005-11-15 11:09 hostkey.pem
</screen>
There.  Now cognito is setup with host and container certs, and it trusts the CA of my grid.  The last step for root is to create a grid-mapfile for myself again:
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>vim grid-mapfile</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>cat grid-mapfile </userinput>
"/O=Grid/OU=GlobusTest/OU=simpleCA-choate.mcs.anl.gov/OU=mcs.anl.gov/CN=Charles Bacon" bacon
</screen>
</para>
</section>

<section id="q-gridftp2"><title>Setting up your second machine: GridFTP</title>
<para>
GridFTP setup on the second machine is identical to the first.  I'll just
list the commands here, see <olink targetptr="q-gridftp"/> for the file contents, or just copy them from the first machine.
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>vim /etc/xinetd.d/gridftp</userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>vim /etc/services </userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>/etc/init.d/xinetd reload</userinput>
Reloading internet superserver configuration: xinetd.
</screen>
Now we can test it:
<screen>
<prompt>crunch %</prompt> <userinput>setenv GLOBUS_LOCATION /usr/local/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>crunch %</prompt> <userinput>source $GLOBUS_LOCATION/etc/globus-user-env.csh</userinput>
<prompt>crunch %</prompt> <userinput>myproxy-logon -s elephant</userinput>
Enter MyProxy pass phrase: <userinput>******</userinput>
A credential has been received for user bacon in /tmp/x509up_u1817.
<prompt>crunch %</prompt> <userinput>globus-url-copy gsiftp://cognito.mcs.anl.gov/etc/group \
   gsiftp://choate.mcs.anl.gov/tmp/from-cognito</userinput>
</screen>
That was a slightly fancier test than I ran on choate.  In this case, I did a third-party transfer between two GridFTP servers.  It worked, so I have the local and remote security setup correctly.
</para>
</section>

<section id="q-container2"><title>Setting up your second machine: Webservices</title>
<para>
Setting up the container on the second machine is a lot like the first.  I'll list the commands here.  See <olink targetptr="q-container"/>, or you can just copy the files from the first machine.  First globus creates the start-stop script:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>vim $GLOBUS_LOCATION/start-stop</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>chmod +x $GLOBUS_LOCATION/start-stop</userinput>
</screen>
Then root creates an init.d script to call it:
<screen>
<prompt>root@cognito:~#</prompt> <userinput>vim /etc/init.d/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>root@cognito:~#</prompt> <userinput>chmod +x /etc/init.d/globus-<replaceable role="entity">version</replaceable></userinput>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>/etc/init.d/globus-<replaceable role="entity">version</replaceable> start</userinput>
Starting Globus container. PID: 17269
</screen>
</para>
</section>

  <section id="q-gram2"><title>Setting up your second machine: GRAM4</title>
<para>
For a change of pace, we'll setup GRAM first on the second machine, even
though we haven't got a working RFT locally.  As with last time, we'll need
to setup the sudoers.  See <olink targetptr="q-gram"/> for the sudo contents, or copy the sudoers from the first machine.
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>visudo</userinput>
</screen>
  Next, however, we'll change the GRAM RFT configuration, using the GRAM docs about setting up "non-default configuration" section of <olink targetdoc="gram4Admin" />:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>vim $GLOBUS_LOCATION/start-stop</userinput>

<prompt>globus@cognito:~$</prompt> <userinput>$GLOBUS_LOCATION/setup/globus/setup-gram-service-common --staging-host=choate.mcs.anl.gov</userinput>
Running /usr/local/globus-<replaceable role="entity">version</replaceable>/setup/globus/setup-gram-service-common
Determining system information...
...
BUILD SUCCESSFUL
Total time: 21 seconds
</screen>
</para>

<para>
Restart the container:
<screen>
<prompt>root@cognito:/etc/grid-security#</prompt> <userinput>/etc/init.d/globus-<replaceable role="entity">version</replaceable> restart</userinput>
Stopping Globus container. PID: 17269
Container stopped
Starting Globus container. PID: 18069
</screen>
Now we can submit a staging job:
<screen>
<prompt>cognito %</prompt> <userinput>vim a.rsl</userinput>
<prompt>cognito %</prompt> <userinput>cat a.rsl</userinput>
cognito % cat a.rsl
<![CDATA[
<job>
    <executable>my_echo</executable>
    <directory>${GLOBUS_USER_HOME}</directory>
    <argument>Hello</argument>
    <argument>World!</argument>
    <stdout>${GLOBUS_USER_HOME}/stdout</stdout>
    <stderr>${GLOBUS_USER_HOME}/stderr</stderr>
    <fileStageIn>
        <transfer>
            <sourceUrl>gsiftp://cognito.mcs.anl.gov:2811/bin/echo</sourceUrl>
            <destinationUrl>file:///${GLOBUS_USER_HOME}/my_echo</destinationUrl>
        </transfer>
    </fileStageIn>
    <fileCleanUp>
        <deletion>
            <file>file:///${GLOBUS_USER_HOME}/my_echo</file>
        </deletion>
    </fileCleanUp>
</job>
]]>
<prompt>cognito %</prompt> <userinput>globusrun-ws -submit -S -f a.rsl</userinput>
Delegating user credentials...Done.
Submitting job...Done.
Job ID: uuid:6732f346-5604-11da-9951-0002b3882c16
Termination time: 11/16/2005 18:19 GMT
Current job state: StageIn
Current job state: Active
Current job state: CleanUp
Current job state: Done
Destroying job...Done.
Cleaning up any delegated credentials...Done.
<prompt>cognito %</prompt> <userinput>cat ~/stdout</userinput>
Hello World!
<prompt>cognito %</prompt> <userinput>ls ~/my_echo</userinput>
ls: /home/bacon/my_echo: No such file or directory
</screen>
This is an example of a staging job.  It copies the /bin/echo command from cognito to my home directory and names it my_echo.  Then it runs it with some arguments, and captures the stderr/stdout.  One of the neat features here is that it used the RFT service on choate to transfer the file via the GridFTP server on cognito.  It's starting to look like a Grid!
</para>
  <para>You can get other examples of GRAM RSL files from <olink targetdoc="gram4User" targetptr="gram4-user-usagescenarios">GRAM usage scenarios</olink>.
</para>
</section>
</section>

<section id="q-vo"><title>VO-level services</title>
<section id="q-index"><title>Setting up an Index Service hierarchy</title>
<para>
Now that we have two machines, we can also setup some information services
to monitor them together.  Let's have cognito register its index service
into choate so we can have an aggregated view of the two machines, as
  described at <olink targetdoc="infoSamples" targetptr="wsmds-samples-DefaultIndexService">Building VOs</olink> in the MDS documentation:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>vim /usr/local/globus-<replaceable role="entity">version</replaceable>/etc/globus_wsrf_mds_index/hierarchy.xml </userinput>
<prompt>globus@cognito:~$</prompt> <userinput>grep upstream $GLOBUS_LOCATION/etc/globus_wsrf_mds_index/hierarchy.xml</userinput>
<![CDATA[
<!-- <upstream> elements specify remote index services that the local index
    Set an upstream entry for each VO index that you wish to participate in.
    <upstream>https://choate.mcs.anl.gov:8443/wsrf/services/DefaultIndexService</upstream>
]]>
root@cognito:~# /etc/init.d/globus-<replaceable role="entity">version</replaceable> restart
Stopping Globus container. PID: 18069
Container stopped
Starting Globus container. PID: 18405
</screen>
Now I can run some index service clients and check that the registration
worked:
<screen>
<prompt>cognito %</prompt> <userinput>setenv JAVA_HOME /usr/java/j2sdk1.4.2_10/</userinput>
<prompt>cognito %</prompt> <userinput>setenv ANT_HOME /usr/local/apache-ant-1.6.5/</userinput>
<prompt>cognito %</prompt> <userinput>setenv PATH $ANT_HOME/bin:$JAVA_HOME/bin:$PATH</userinput>
<prompt>cognito %</prompt> <userinput>host cognito</userinput>
cognito.mcs.anl.gov has address 140.221.8.109
<prompt>cognito %</prompt> <userinput>wsrf-query -s https://choate.mcs.anl.gov:8443/wsrf/services/DefaultIndexService '/*' | grep 140.221.8.109 | wc -l</userinput>
7
</screen>
So we've got seven entries in the remote index that reference our machine.  That means our upstream registration was processed successfully.  But what do those entries look like?  Here's an example:
<screen>
<![CDATA[
      <ns15:Address xmlns:ns15="http://schemas.xmlsoap.org/ws/2004/03/addressing">
https://140.221.8.109:8443/wsrf/services/ManagedJobFactoryService</ns15:Address>
]]>
</screen>
  It's hard to read, isn't it?  That's an entry in choate that points to the GRAM4 service running on cognito that we just setup.  But our life would be easier if we setup WebMDS to visualize the contents of the Index Service.  So let's do that next.
</para>
<note><para>
Notice that I hadn't setup my java variables yet, but the GRAM client above
worked just fine.  That's because it's written in C, even though it interacts
with the java container.  Language neutrality is one of the features of
webservices.
</para></note>
</section>

<section id="q-webmds"><title>Configuring WebMDS</title>
<para>
WebMDS has a dependency on the Tomcat container, so we'll install that now.  The recommended version is 5.0.28, which is available from the Apache Tomcat website.  We're following the standard install instructions from the <olink targetdoc="webmdsAdmin" targetptr="webmds-configuring">WebMDS Admin Guide</olink>.
<screen>
<prompt>root@cognito:/usr/local#</prompt> <userinput>tar xzf jakarta-tomcat-5.0.28.tar.gz </userinput>
<prompt>root@cognito:/usr/local#</prompt> <userinput>chown -R globus:globus jakarta-tomcat-5.0.28</userinput>
</screen>
Now the globus user can configure WebMDS:
<screen>
<prompt>globus@cognito:~$</prompt> <userinput>vim $GLOBUS_LOCATION/lib/webmds/conf/indexinfo</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>grep choate /usr/local/globus-<replaceable role="entity">version</replaceable>/lib/webmds/conf/indexinfo</userinput>
    &lt;value&gt;https://choate.mcs.anl.gov:8443/wsrf/services/DefaultIndexService&lt;/value&gt;
<prompt>globus@cognito:~$</prompt> <userinput>export CATALINA_HOME=/usr/local/jakarta-tomcat-5.0.28</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>$GLOBUS_LOCATION/lib/webmds/bin/webmds-create-context-file \</userinput>
          <userinput>$CATALINA_HOME/conf/Catalina/localhost</userinput>
<prompt>globus@cognito:~$</prompt> <userinput>$CATALINA_HOME/bin/startup.sh</userinput>
Using CATALINA_BASE:   /usr/local/jakarta-tomcat-5.0.28
Using CATALINA_HOME:   /usr/local/jakarta-tomcat-5.0.28
Using CATALINA_TMPDIR: /usr/local/jakarta-tomcat-5.0.28/temp
Using JAVA_HOME:       /usr/java/j2sdk1.4.2_10/
</screen>
That started Tomcat on port 8080, so now I can browse to the /webmds directory on that port of my machine (http://cognito.mcs.anl.gov:8080/webmds/ but that's behind a firewall.  You can visit your own machine, though).  Now I can read the info stored in the index in human-readable format.  For instance, I can see this:
<screen>
RFT	140.221.8.31	0 active transfer resources, transferring 0 files.
26.06 KB transferred in 2 files since start of database.
</screen>
Those two RFT transfers were the one I ran by hand in the RFT section, then the RFT transfer that happened because of my GRAM job that used file staging.  I can also see some information about my GRAM services:
<screen>
GRAM	140.221.8.109	1 queues, submitting to 0 cluster(s) of 0 host(s).
</screen>
If I click for details, I get:
<screen>
ComputingElement:
Name: default
UniqueID: default
Info:
TotalCPUs: 1
</screen>
This works because the GRAM and RFT services are configured to register into the local service automatically.  When we edited the hierarchy.xml file to point to choate, all the information started to be cached centrally.
</para>
</section>
</section>
  <glossary role="auto" id="glossary-quickstart">
    <glossdiv><title>A</title>
      <glossentry>
        <glossterm>Irrelevant</glossterm>
        <glossdef>
          <para>If you can see this, the document was processed incorrectly. Use the
            <parameter>glossary.collection</parameter> parameter.</para>
        </glossdef>
      </glossentry>
    </glossdiv>
  </glossary>
</article>

