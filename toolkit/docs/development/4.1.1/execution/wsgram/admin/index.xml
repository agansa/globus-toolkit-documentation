<title>GT 4.0 WS GRAM : System Administrator's Guide</title>
<titleabbrev> System Administrator's Guide</titleabbrev>
 
<section id="s-wsgram-admin-introduction"><title>Introduction</title>

<para>This guide contains advanced configuration information
  for system administrators working with WS GRAM. It provides references to
  information on procedures typically performed by system administrators,
  including installation, configuring, deploying, and testing the
  installation. It also describes additional prerequisites and host settings
  necessary for WS GRAM operation. Readers should be familiar with the
  <ulink url="../../execution/key/index.html">Key Concepts</ulink> and
  <ulink url="../../execution/key/WS_GRAM_Approach.html">Implementation Approach</ulink>
  for WS GRAM to understand the motivation for and interaction between the
  various deployed components.
</para>


  <important>
 <simpara> The information in this WS GRAM Admin Guide is in addition to the basic Globus Toolkit prerequisite, 
    overview, installation, security configuration instructions in the <ulink url="../../admin/docbook/">GT 4.0 System Administrator's Guide</ulink>.  
    Read through this guide before continuing!</simpara>  
  </important>

</section>
<!-- introduction -->

<section id="s-wsgram-admin-installing"><title>Building and Installing</title>
  <para>WS GRAM is built and installed as part of
    a default GT 4.0 installation. For basic installation instructions, see the
    <ulink url="../../admin/docbook/">GT 4.0 System Administrator's Guide</ulink>.</para>
  
<section id="s-wsgram-admin-installing-req"><title>Installation Requirements</title>

<section id="s-wsgram-admin-security"><title>Transport Level Security (TLS)</title>
<para>
  In order to use WS GRAM, the container must be started with Transport Level
  security.  The "-nosec" option should *not* be used with
  <computeroutput>globus-start-container</computeroutput>.
</para>
</section>
  <!-- transport level security -->

<section id="s-wsgram-admin-sudo"><title>Functioning sudo</title> <para>
  WS GRAM requires that the <computeroutput>sudo</computeroutput> command is
  installed and functioning on the service host where WS GRAM software will
  execute.
</para>
<para>
  Authorization rules will need to be added to the
  <computeroutput>sudoers</computeroutput> file to allow the WS GRAM service
  account to execute (without a password) the scheduler adapter in the
  accounts of authorized GRAM users.  For configuration details, see the
  <link linkend="s-wsgram-admin-configsudo">Configuring sudo</link> section.
</para>
<para>
   Platform Note: On AIX, sudo is not installed by default, but it is available as source and rpm here: 
  <ulink url="http://www-1.ibm.com/servers/aix/products/aixos/linux/download.html">AIX 5L Toolbox for Linux Applications</ulink>
</para>
</section>
  <!-- functioning sudo -->

<section id="s-wsgram-admin-localscheduler"><title>Local scheduler</title>
<para> 
  WS GRAM depends on a local mechanism for starting and controlling jobs.
  Included in the WS GRAM software is a Fork "scheduler", which requires no
  special software installed to execute jobs on the local host.  However, to
  enable WS GRAM to execute and manage jobs to a batch scheduler, the scheduler
  software must be installed and configured prior to configuring WS GRAM.

  The WS GRAM scheduler adapters (interface to the batch schedulers) included
  in the GT 4.0 release are:
  <ulink url="http://www.openpbs.org/">PBS</ulink>,
  <ulink url="http://www.cs.wisc.edu/condor/">Condor</ulink>,
  <ulink url="http://www.platform.com/products/LSF/">LSF</ulink>

  Scheduler adapters that we have For configuration details, see the
  <link linkend="s-wsgram-admin-configuringscheduleradapters">Configuring scheduler adapters</link> section.
</para>
<para>
  Other scheduler adapters that we know of are: <ulink url="http://www.doc.ic.ac.uk/~dwm/Code/sge-gt4/">Sun Grid Engine</ulink>
</para>


</section>
  <!-- local scheduler -->

<section id="s-wsgram-admin-rft"><title>Reliable File Transfer Service (RFT)</title>
<para> 
  WS GRAM depends on RFT to perform file staging and cleanup directives in 
  a job description.  For configuration details, see the
  <ulink url="../../data/rft/admin/">RFT admin guide</ulink>
  <emphasis>Important:</emphasis> Jobs requesting these functions will fail if
  RFT is not properly setup.
</para>
</section>
  <!-- RFT -->

</section>
<!-- Installation Requirements -->
</section>
<section id="s-wsgram-admin-configuring"><title>Configuring </title>
<section id="s-wsgram-admin-configuring-typical"><title>Typical Configuration</title>

<section id="s-wsgram-admin-configsudo"><title>Configuring sudo</title>
<para>When the credentials of the service account and the job submitter are different
  (multi user mode), then GRAM will prepend a call to sudo to the local adapter
  callout command. <emphasis>Important:</emphasis> If sudo is not configured properly, the command
  and thus job will fail.</para>
<para>
  As <emphasis>root</emphasis>, here are the two lines to add to the
  /etc/sudoers file for each GLOBUS_LOCATION installation, where
  /opt/globus/GT4.0.0 should be replaced with the GLOBUS LOCATION for your
  installation:
<screen># Globus GRAM entries
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /etc/grid-security/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-job-manager-script.pl *
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /etc/grid-security/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-gram-local-proxy-tool *
</screen>

</para>
<para>
  The <computeroutput>globus-gridmap-and-execute</computeroutput> program is
  used to ensure that GRAM only runs programs under accounts that are in the
  grid-mapfile.  In the sudo configuration, it is the first program called
  before any other program.  It looks up the account in the grid-mapfile and
  then runs the requested command.  It is redundant if sudo is properly locked
  down.  This tool could be replaced with your own authorization program.
</para>
</section>
  <!-- Configuring sudo -->

<section id="s-wsgram-admin-configuringscheduleradapters"><title>Configuring Scheduler Adapters</title>
<para>
  The WS GRAM scheduler adapters included in the release tarball
  are: PBS, Condor and LSF. To install, follow these steps (shown for pbs):

<screen>    % cd $GLOBUS_LOCATION\gt4.0.0-all-source-installer

    % make gt4-gram-pbs

    % make install

</screen>
</para>
<para>
  Using PBS as the example, make sure the scheduler commands are in your
  path (qsub, qstat, pbsnodes).
</para>
<para> For PBS, another setup step is required to configure the remote shell for
  rsh access: 

<screen>

    % cd $GLOBUS_LOCATION/setup/globus

    % ./setup-globus-job-manager-pbs --remote-shell=rsh

</screen>
</para>
<para>
  The last thing is to define the <link linkend="s-wsgram-Interface_Config_Frag-filesysmap">GRAM 
    and GridFTP file system mapping</link> for PBS.  A default
  mapping in this file is created to allow simple jobs to run.  However, the
  actual file system mappings for your compute resource should be entered to
  ensure:
    <itemizedlist>
       <listitem><para>files staging is performed correctly
            </para>
       </listitem>
       <listitem><para>
            </para>jobs with erroneous file path directives are rejected
       </listitem>
    </itemizedlist>
</para>
<para>
  Done! You have added the PBS scheduler adapters to your GT installation.
</para>
<para>
    Note for future GT builds with scheduler adpaters: scheduler adapters can
    be enabled by adding --enable-wsgram-pbs to the configure line when
    building the entire toolkit.
<screen>
    % configure --prefix=$GLOBUS_LOCATION --enable-wsgram-pbs ...
    % make
    % make install
</screen>
</para>
</section>
  <!-- enabling scheduler adapters -->

</section>
<!-- Typical Configuration -->

<section id="s-wsgram-admin-configuring-nondefault"><title>Non-default Configuration</title>

<section id="s-wsgram-admin-userproxy"><title>Non-default Credentials</title>
<para>
  To run the container using just a user proxy, instead of host creds,
  simply comment out the ContainerSecDesc parameter in this file 
  <computeroutput>$GLOBUS_LOCATION/etc/globus_wsrf_core/server-config.wsdd</computeroutput> as
  follows:
<screen>
    &lt;!--
        &lt;parameter 
            name="containerSecDesc" 
            value="etc/globus_wsrf_core/global_security_descriptor.xml"/&gt;
     --&gt;
</screen>
  Running in personal mode (user proxy), another GRAM configuration setting
  is required. For GRAM to authorize the RFT service when performing
  staging functions, it needs to know the subject DN for verification. Here are
  the steps:
<screen>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-subject=
         "/DC=org/DC=doegrids/OU=People/CN=Stuart Martin 564720"
      </screen>
You can get your subject DN by running this command:
<screen>
	% grid-cert-info -subject
</screen>
</para>
</section>
  <!-- Non-default Credentials -->

<section id="s-wsgram-admin-nondefaultgridftp"><title>Non-default GridFTP server </title>
<para>
  By default, the GridFTP server is assumed to run as root on localhost:2811.
  If this is not true for your site then change it by editting the GridFTP host
  and/or port in the <link linkend="s-wsgram-Interface_Config_Frag-filesysmap">GRAM and GridFTP file system mapping</link> config file: <computeroutput>$GLOBUS_LOCATION/etc/gram-service/globus_gram_fs_map_config.xml</computeroutput>.
</para>

</section>
  <!-- Non-default GridFTP server -->

<section id="s-wsgram-admin-nondefaultcontainerport"><title>Non-default container port</title>
<para>
  By default, the globus services will assume 8443 is the port the Globus
  container is using.  However the container can be run under a non-standard
  port, for example:
<screen>
	% globus-start-container -p 4321
</screen>
  When doing this, GRAM needs to be told the port to use to contact the RFT
  service, like so:
<screen>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-port="4321"
</screen>
</para>
</section>
  <!-- Non-default container port -->

<section id="s-wsgram-admin-nondefaultgridmap"><title>Non-default gridmap</title>
<para>
  If you wish to specify a non-standard gridmap file in a multi-user
  installation, two basic configurations need to be changed:</para>

<itemizedlist>
    <listitem><para>$GLOBUS_LOCATION/etc/globus_wsrf_core/global_security_descriptor.xml
      <itemizedlist><listitem><simpara>As specified in the <ulink url="../../security/authzframe/security_descriptor.html#s-authzframe-secdesc-configGridmap">gridmap config</ulink> instructions, add a &lt;gridmap value="..."/&gt;
                element to the file appropriately.</simpara></listitem>
	</itemizedlist>
    </para></listitem>

    <listitem><para>/etc/sudoers
        <itemizedlist>
            <listitem><para>Change the file path after all -g options<screen>-g /path/to/grid-mapfile</screen>.
            </para></listitem>
        </itemizedlist>
    </para></listitem>
</itemizedlist>

<para>
Example:

<emphasis>global_security_descriptor.xml</emphasis>
<screen>
    ...

    &lt;gridmap value="/opt/grid-mapfile"/&gt;

    ...
</screen>
<emphasis>sudoers</emphasis>
<screen>
   ...

   # Globus GRAM entries
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /opt/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-job-manager-script.pl *
   globus  ALL=(username1,username2) 
           NOPASSWD: /opt/globus/GT4.0.0/libexec/globus-gridmap-and-execute 
           -g /opt/grid-mapfile
           /opt/globus/GT4.0.0/libexec/globus-gram-local-proxy-tool *

    ...
</screen>
</para>
</section>
  <!-- Non-default gridmap file -->

<section id="s-wsgram-admin-nondefaultjoblimit"><title>Non-default job resource limit</title>
<para>The current limit on the number of job resources (both exec and multi)
allowed to exist at any one time is 1000.  This limit was chosen from
scalability tests as an appropriate precaution to avoid out-of-memory errors.
To change this value to, say, 150, use the setup-gram-service-common script as follows:</para>
<screen>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --max-job-limit="150"
</screen>
</section> 
  <!-- Non-default job resource limit -->

</section>
<!-- Non-default Configuration -->
</section>

<section id="s-gridftp-admin-deploying"><title>Deploying </title>
  <para>WS GRAM is deployed as part of a standard toolkit installation. 
    Please refer to  the <ulink url="../../admin/docbook/">GT 4.0 System Adminstrator's Guide</ulink> for details.</para>
  </section>

<section id="s-wsgram-admin-testing"><title>Testing</title>
	<para>See the WS GRAM <ulink url="../../execution/wsgram/user-index.html#s-wsgram-user-usagescenarios">User's Guide</ulink> for information about submitting a test job.</para>
</section>


<section id="s-wsgram-admin-security_considerations"><title>Security Considerations </title>
&WS_GRAM_Security_Considerations_Frag;
</section>

<section id="s-wsgram-admin-troubleshooting"><title>Troubleshooting</title>
&WS_GRAM_Troubleshooting_Frag;
</section>

<section id="s-wsgram-admin-usage"><title>Usage statistics collection by the Globus Alliance</title>
&WS_GRAM_Usage_Statistics_Frag;
</section>
