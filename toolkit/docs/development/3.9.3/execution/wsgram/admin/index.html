<?php include_once( "/mcs/www-unix.globus.org/include/globus_header.inc" ); ?>

<h1>GT 3.9.3 WS GRAM : System Administrator's Guide</h1>
<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li> <a href="#installing">Building and Installing</a></li>
  <li><a href="#configuring">Configuring</a></li>
  <li><a href="#testing">Testing</a></li>
  <li><a href="#troubleshooting">Troubleshooting</a></li>
</ul>
<h2><a name="introduction"></a>Introduction</h2>
<p>This document describes the installation and deployment of WS_GRAM including
  administrator-selected features, configuration options, and additional host
  settings necessary for WS_GRAM operation. Readers should be familiar with the <a href="../WS_GRAM_Key_Concepts.html">Key
  Concepts</a> and <a href="../WS_GRAM_Approach.html">Implementation Approach</a> for
  WS_GRAM to understand the motivation for and interaction of the various deployed
components.</p>
<p>For basic instructions on installing GT 3.9.3, see the <a href="../../../admin/">Installation
Guide</a>. </p>
<h2><a name="installing"></a>Building and Installing</h2>
<h3>Local Prerequisites</h3>
<p>WS_GRAM requires the following:</p>
<ul>
  <li><a href="#hostcredentials">Host credentials</a></li>
  <li><a href="#serviceaccount">GRAM service account </a></li>
  <li><a href="#sudo">Functioning sudo</a></li>
  <li><a href="#localscheduler">Local scheduler </a></li>
</ul>

<h4><a name="hostcredentials"></a>Host credentials</h4>
<p> In order to use WS_GRAM, the services running in the WSRF hosting environment require access to an appropriate host certificate.

</p>

<h4><a name="serviceaccount"></a>GRAM service account</h4>
<p> WS_GRAM requires a dedicated local account within which the WSRF hosting
  environment and GRAM services will execute. This account will often be a <code>globus</code> account used for all local services, but may also be specialized to only host WS_GRAM.
  User jobs will run in separate accounts as specified in the <code>grid-mapfile</code> or associated authorization policy configuration of the host. </p>
<p>

<h4><a name="sudo"></a>Functioning sudo</h4>
<p> WS_GRAM requires that the <code>sudo</code> command is installed and functioning
  on the service host where WS_GRAM software will execute. </p>
<p> Authorization rules will need to be added to the <code>sudoers</code> file to allow the WS_GRAM service account
  to execute (without a password) local scheduler adapters in the accounts of
  authorized GRAM users. This topic is covered in detail in the Software Setup
  section. </p>

<h4><a name="localscheduler"></a>Local scheduler</h4>
<p> WS_GRAM depends on a local mechanism for starting and controlling jobs. If
  the fork-based WS_GRAM mode is to be used, no special software is required.
  For batch scheduling mechanisms, the local scheduler must be installed and
  configured for local job submission prior to deploying and operating WS_GRAM.
  The supported batch schedulers in the GT 3.9.3 release are: PBS, Condor, LSF</p>

<p> RFT prerequisites include PostgreSQL to be installed and configured. The
  instructions are <a href="../../../data/rft/admin/index.html">here</a>
    GRAM depends on RFT for file staging and cleanup. File staging from client host to compute host and visa versa.  Jobs requesting these function will fail Without RFT properly setup. </p>

<h3><a name="fullinstall"></a>Full GT4 Installation including WS_GRAM</h3>
<p>
    <li>Download and expand the full GT source tarball
    <li>Build source</li>
<pre>
        % wget &lt;GT tarball location&gt;/gt3.9.3-wsrf-source-installer.tar.gz
        % cd gt3.9.3-wsrf-source-installer
        % install-wsrf &lt;install directory&gt;
</pre>
    <li>Done!  You have a full Globus Toolkit install including WS_GRAM - with the default configuration. 

<h2><a name="configuring"></a>Configuring </h2>
<p>Information on configuration settings and environment variables can be found
  in the <a href="../WS_GRAM_Public_Interfaces.html">public interface guide</a>.</p>

<h3>Enabling Local Scheduler Adapter</h3>
<p>The batch scheduler interface implementations included in the release tarball are: PBS, Condor and LSF.  To install one of the batch scheduler adapters, follow these steps:</p>

<pre>
        % cd gt3.9.3-wsrf-source-installer
	% cd schedulers
	% ls
</pre>

gives the following output:

<pre>
gt4-gram-condor-3.9-src_bundle.tar.gz
gt4-gram-lsf-3.9-src_bundle.tar.gz
gt4-gram-pbs-3.9-src_bundle.tar.gz
</pre>

Using PBS as the example, make sure the batch scheduler commands are in your path (qsub, qstat, pbsnodes).  Then to build and install the PBS bundle type these commands:
<pre>
	% gpt-build gt4-gram-pbs-3.9-src_bundle.tar.gz gcc32dbg
	% gpt-postinstall
</pre>

Last thing is to define the <a href="../WS_GRAM_Public_Interfaces.html#filesysmap">GRAM and GridFTP file system mapping</a> for PBS.

<p>
Done!  You have added the PBS scheduler adapters to your GT installation.

<h3>Configuring sudo</h3>
  When the credentials of the service account and the job submitter are different (multi user mode), then GRAM will prepend a call to sudo to the local adapter callout command.  If sudo is not configured properly, the command and thus job will fail.
<br>
As <b>root</b>, here are the two lines to add to the /etc/sudoers file for each GLOBUS_LOCATION installation, where /opt/globus/GT393 should be replaced with the GLOBUS LOCATION for your installation:

<pre>
   # Globus GRAM entries
   globus  ALL=(username1,username2) NOPASSWD: /opt/globus/GT393/libexec/globus-gridmap-and-execute /opt/globus/GT393/libexec/globus-job-manager-script.pl *
   globus  ALL=(username1,username2) NOPASSWD: /opt/globus/GT393/libexec/globus-gridmap-and-execute /opt/globus/GT393/libexec/globus-globus-gram-local-proxy-tool *
</pre>

<h3>Extra steps for non-default installation</h3>

<h4>service credentials</h4>
  In a default build and install of the Globus Toolkit, the local account is configured to use host credentials at /etc/grid-service/containercert.pem and containerkey.pem.  If this is not an option, then you can configure an alternate location to point to host credentials -or- configure to use just a user proxy (personal mode).
<p>
  Security descriptor configuration details are <a href="../../../security/authzframe/security_descriptor.html#descFile">here</a>, but the quick change is to edit this file <tt>$GLOBUS_LOCATION/etc/globus_wsrf_core/global_security_descriptor.xml</tt>.  Change the cert and key paths to point to host credentials that the service account owns.

  To run the container using just a user proxy, simply comment out the ContainerSecDesc parameter in the this file <tt>$GLOBUS_LOCATION/etc/globus_wsrf_core/server-config.wsdd</tt> like so:
<pre>
    &lt;!--
        &lt;parameter 
            name="containerSecDesc" 
            value="etc/globus_wsrf_core/global_security_descriptor.xml"/&gt;
     --&gt;
</pre>

  Running in personal mode (user proxy), another GRAM configuration setting is required.  GRAM will authorize the RFT service when performing staging functions, it needs to know the subject DN for verification.  Here are the steps:

<pre>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-subject="/DC=org/DC=doegrids/OU=People/CN=Stuart Martin 564720"
</pre>

You can get your subject DN by running this command:
<pre>
	% grid-cert-info -subject
</pre>

<h4>GridFTP server </h4>
  By default, the GridFTP server is assumed to run as root on localhost:2811.  If this is not true for your site then change it by running this command with the proper GridFTP URL values:

<pre>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --gridftp-server=gsiftp://gridftp.host.org:1234"
</pre>

Also, the GridFTP host and/or port must be updated by editing the <a href="../WS_GRAM_Public_Interfaces.html#filesysmap">GRAM and GridFTP file system mapping</a> config file <tt>$GLOBUS_LOCATION/etc/gram-service/globus_gram_fs_map_config.xml</tt>.
<p>
 
<h4>non-default container port</h4>
  By default, the globus services will assume 8080 is the port the Globus container is using.  However the container can be run under a non-standard port, for example:
<pre>
	% globus-start-container -p 4321
</pre>

When doing this, GRAM needs to be told the port to use to contact the RFT service, like so: 
<pre>
	% cd $GLOBUS_LOCATION/setup/globus
	% ./setup-gram-service-common --staging-port="4321"
</pre>


<h2><a name="testing"></a>Testing</h2>
See the WS GRAM <a href="../user/commandline_java_managed_globus_run.html#interactivemode">users guide</a> for submitting a test job.

<h2><a name="troubleshooting"></a>Troubleshooting</h2>
<p>&nbsp;</p>

<?php include("/mcs/www-unix.globus.org/include/globus_footer_dev_docs.inc"); ?>
