<?xml version='1.0' encoding='UTF-8'?>

<para>
<emphasis>When I submit a streaming or staging job, I get the following error:

ERRORã€€service.TransfreWork Terminal transfer error:
[Caused by: Authentication failed[Caused by: Operation unauthorized(Mechanism le
vel: Authorization failed. Expected"/CN=host/localhost.localdomain" target but r
eceived "/O=Grid/OU=GlobusTest/OU=simpleCA-my.machine.com/CN=host/my.machine.com
")
</emphasis>
</para>
<itemizedlist>
    <listitem><simpara>Check $GLOBUS_LOCATION/etc/globus_wsrf_gram_service_java/globus_gram_fs_map_config.xml for the use of "localhost" or "127.0.0.1" instead
    of the public hostname (in the example above, "my.machine.com").
    Change these uses of the loopback hostname or IP to the public hostname as
    neccessary.</simpara></listitem>
</itemizedlist>

<para>
<emphasis>Fork jobs work fine, but submitting PBS jobs with globusrun-ws hangs at "Current job state: Unsubmitted"</emphasis>
</para>
<itemizedlist>
    <listitem><simpara>Make sure the the log_path in
    $GLOBUS_LOCATION/etc/globus-pbs.conf points to locally accessible scheduler
    logs that are readable by the user running the container.  The Scheduler
    Event Generator (SEG) will not work without local scheduler logs to monitor.
    This can also apply to other resource managers, but is most comonly seen
    with PBS.
    </simpara></listitem>
    <listitem><simpara>If the SEG configuration looks sane, try running the SEG
    tests. They are located in
    $GLOBUS_LOCATION/test/globus_scheduler_event_generator_*_test/. If Fork jobs
    work, you only need to run the PBS test. Run each test by going to the
    associated directory and run ./TESTS.pl. If any tests fail, report this to
    the gram-dev@globus.org mailing list.
    </simpara></listitem>
    <listitem><simpara>If the SEG tests succeed, the next step is to figure out
    the ID assigned by PBS to the queued job. Enable GRAM debug logging by
    uncommenting the appropriate line in the
    $GLOBUS_LOCATION/container-log4j.properties configuration file.
    Restart the container, run a PBS job, and search the container log for a
    line that contains "Received local job ID" to obtain the local job ID.
    </simpara></listitem>
    <listitem><simpara>Once you have the local job ID you can check the latest
    PBS logs pointed to by the value of "log_path" in
    $GLOBUS_LOCATION/etc/globus-pbs.conf to make sure the job's status is being
    logged. If the status is not being logged, check the documentation for your
    flavor of PBS to see if there's any futher configuration that needs to be
    done to enable job status logging. For example, PBS Pro requires a
    sufficient -e &lt;bitmask&gt; option added to the pbs_server command line to
    enable enough logging to satisfy the SEG.
    </simpara></listitem>
    <listitem><simpara>If the correct status is being logged, try running the
    SEG manually to see if it is reading the log file properly. The general
    form of the SEG command line is as follows:

    <computeroutput>
    $GLOBUS_LOCATION/libexec/globus-scheduler-event-generator -s pbs -t &lt;timestamp&gt;
    </computeroutput>

    The timestamp is in seconds since the epoch and dictates how far back in the
    log history the SEG should scan for job status events. The command should
    hang after dumping some status data to stdout. If no data appears, change
    the timestamp to an earlier time. If nothing ever appears, report this to
    the gram-user@globus.org mailing list.
    </simpara></listitem>
    <listitem><simpara>If running the SEG manually succeeds, try running another
    job and make sure the job process actually finishes and PBS has logged the
    correct status before giving up and cancelling globusrun-ws. If things are
    still not working, report your problem and exactly what you have tried to
    remedy the situtation to the gram-user@globus.org mailing list.
    </simpara></listitem>
</itemizedlist>

<para>
<emphasis>The job manager detected an invalid script response</emphasis>
</para>
<itemizedlist>
    <listitem><simpara>Check for a restrictive umask. When the service writes the native
        scheduler <glossterm>job description</glossterm> to a file, an overly restrictive umask will
        cause the permissions on the file to be such that the submission
        script run through <glossterm baseform="superuser do">sudo</glossterm> as the user cannot read the file (bug #2655).
    </simpara></listitem>
</itemizedlist>

<para>
<emphasis>When restarting the container, I get the following error:
Error getting delegation resource</emphasis>
</para>
<itemizedlist>
    <listitem><simpara>Most likely this is simply a case of the delegated
    credential expiring.  Either refresh it for the affected job or destroy
    the job resource.
    </simpara></listitem>
</itemizedlist>
