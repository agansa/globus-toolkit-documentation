<?php

$title = "CAS: System Administrator's Guide";

include_once( "/mcs/www-unix.globus.org/include/globus_header.inc" ); ?>


<p class="small"><a href="http://www.globus.org">Globus</a> &gt; <a href="http://www-unix.globus.org/toolkit/">Toolkit</a> &gt; <a href="http://www-unix.globus.org/toolkit/docs/">Documentation</a> &gt; <a href="../../index.html">3.2</a> &gt; <a href="../index.html">CAS</a> &gt; System
  User's Guide &lt; </p>
<h1>CAS: User's Guide</h1>
<p class="small"><a href="index.html">Overview</a><br>
    <a href="casproxyinit.html">Generating CAS credentials (cas-proxy-init) </a><br>
    <a href="caswrap.html">Using CAS credentials (cas-wrap)</a><br>
    <a href="casservicedata.html">CAS Service Data</a><br>
    <a href="writingcasclients.html">Writing CAS clients</a><br>
  &gt;Performance Measurements
<h2><a name="performance">Performance Tests </a></h2>
<h3>Summary of performance tests </h3>
<ul>
  <li>Basic query test - <em>whoami </em>
  <li>Query test - <em>findPolicyData </em>
  <li>Credential test - <em>getMaximalAssertion </em>
  <li>Size of credential test </li>
</ul>
<p>Each of the first three tests were done once with 200 clients talking to the
  server serially and then with all them talking to the server concurrently.
  Each number is an average of the time taken to get a locator and handle to
  the CASPort and the actual method invocation. All numbers are in milliseconds.
<p>The stress test framework in GT3.2 Core was used for testing. This framework
  allows a block of code defined in an "init" method for initializing, code to
  be timed in "run" method and finally a "postRun" methd. Two of the numbers
  the stress framework that are of relevance here are
<ul>
  <li>"totalAverageTime" - this is the average time that each performance run
    takes (initialization, run and postRun). In the table below, these are the
    numbers given outside the bracket. (appears to be weird in concurent case
    since it does not account for the large time each thread takes).
  <li>"totalCallAverageTime" - this is the average time that each run of the
      relevant code takes (run). In the table below, these are the numbers given
      inside the bracket. In concurent runs, the time taken are very high.But
      look at end of this document to see what infrastructure contributes.) </li>
</ul>
<p>The server and client were run on the same machine. Database (PostGres) was
  used and was also on the same machine.
<h3>Platform </h3>
All tests were run on a i686, 2.2GHz machine running Linux 2.4.18.
<h3>Database status </h3>
<p>All tests were run with two different sets of data in the backend database.
  But in both cases the default bootstrap was done which populated the database
  with service/action implict to CAS service.
<p>In the case of smaller data set, other than the data described above, a single
  trust anchor, usergroup, user and object was added. Two policies were added
  - one granting that user group super user permissions on the CAS server and
  another granting it access to the external object added. (only the latter is
  returned on an assertion generation request.)
<p>In the other case, 100 user groups, 100 users, 100 resources and 1000 polices
  was added above the deafult data. Each user group was given ten polices across
  the resources.
<h3>Test results </h3>
<blockquote>
  <h4>Basic query test </h4>
  <p>This test measures the time taken to query the database to get the CAS
        nickname of the user making the call. There are no parameters to process
        in this call and is the most rudimentary query in the CAS service. Every
        single CAS invocation does this to get the name of the user to ascertain
        permissiosns.
  </p>
  <p>The test was run with 200 client threads, serially and cocurrently.
  </p>

            <table>
              <tr>
                <td></td>
                <td>Serial </td>
                <td></td>
                <td>Concurrent </td>
              </tr>
              <tr>
                <td>Small </td>
                <td></td>
                <td>253 (253) </td>
                <td></td>
                <td>155(26832) </td>
              </tr>
              <tr>
                <td>Large </td>
                <td></td>
                <td>253(253) </td>
                <td></td>
                <td>214(40958) </td>
                <td></td>
              </tr>
  </table>
            <h4>Query test </h4>
            <p>This test measures the time taken to query the database to get all applicable
            policy for the user making the call. The CAS server checks permissions
            for the operation and performs the actual retrieval of policy and is returned
            as an array of PolicyData objects.
  </p>
            <p>The test was run with 200 client threads, serially and cocurrently.
                With smaller data set only one policy is returned, with larger dataset
                10 amongst the 1000 policies are returned.
  </p>
            
        
<table>
      <tr>
        <td>
        <td>Serial
        <td>
        <td>Concurrent
        <td></td>
      <tr>
        <td>Small
        <td>
        <td>315(315)
        <td>
        <td>219(34425)
        <td></td>
      <tr>
        <td>Large
        <td>
        <td>479(479)
        <td>
        <td>286(40298)
        <td></td>
      </tr>
  </table>
 
          <h4>Credential test </h4>
          <p>This test measures the time taken to query the database to get all applicable
            assertions for the user making the invocation. The CAS server checks permissions
            for the operation and performs the actual retrieval of assertion. Since
            the assertion is returned as xsd:any the time taken to convert them in
            SAMLAssertion object is also measure.
  </p>
          <p>The test was run with 200 client threads, serially and cocurrently.
                With smaller data set assertion contains only one authorizatin policy
                , with larger dataset 10 polices amongst the 1000 policies are embedded
                in the assertion.
  </p>

<table>
      <tr>
        <td>
        <td>Serial
        <td>
        <td>Concurrent
        <td></td>
      <tr>
        <td>Small
        <td>
        <td>416(416)
        <td>
        <td>303(50032)
        <td></td>
      <tr>
        <td>Large
        <td>
        <td>568(568)
        <td>
        <td>400(52304)
        <td></td>
      </tr>
  </table>

          <h4>Size of credential test </h4>
          <p>The database was populated appropraitely to generate credentials of various
          sizes and saved to file. The largest credential size tested was approximately
          70K. This required that the default timeout in the Stub be incresed to allow
          for large call time.
  </p>
          <p>For credendial of size 70995, using 50 threads serially, the avarage timetaken
            was 6833ms. </p>
</blockquote>
          <h3>Running performance tests </h3>
          <blockquote>
            <p>All the classes needed to run these tests are in the package <em>org.globus.ogsa.impl.base.cas.server.test.performance </em> and
    targets have been provided in the build file for running them.
            </p>
          </blockquote>
<h5>Setting up database </h5>
<blockquote>
  <p>These targets add some specific number of users to the database. One of
    the users needs to have the subect DN of the credential that will be used
    while running the tests. This is picked up from a variable "subject1DN" from a file,
    whose name is passes as a system property to each of this target. But default,
    this is set to "casTestProperties". To override it, set <em>-Dcas.test.properties </em> while
    invoking the target.
  </p>
  <p>To get configuration parameters for database access, a file with database
    information is required as shown <a href="http://www-unix.globus.org/Security/CAS/GT3/docs/installGuide.html#dbConfig">here </a>.
    This is by default, "casDBProperties". To override it, set <em>-Dcas.db.properties </em> while
    invoking the target.
  </p>
  <p>To set up small datasets in database, the following from CAS_HOME psql -U
    tester -d casDatabase -f etc/delete.sql <br>
    ant bootstrap <br>
    ant populateDB -Dargs="small"
  </p>
  <p>To set up large datasets, but credential size less than 50K, in database,
    the following from CAS_HOME psql -U tester -d casDatabase -f etc/delete.sql <br>
    ant bootstrap <br>
    ant populateDB -Dargs="large"
  </p>
  <p>To set up large datasets, but credential size greater than 50K, in database,
    the following from CAS_HOME psql -U tester -d casDatabase -f etc/delete.sql <br>
    ant bootstrap <br>
    ant populateDB -Dargs="large largeCred"
  </p>
</blockquote>
<h2><a name="gt3Cont">Setting up GT3.2 container </a></h2>
For large runs (greater than 200 clients) and/or large credential generation(greater
than 50K), the default timout on the Stub needs to be altered. This can be done
by editing the GLOBUS_LOCATION/build.xml, <em>stress </em> target and adding
the following as another system property. The value needs to be set appropriately. &lt;sysproperty
key="org.globus.ogsa.client.timeout" value="200000"/&gt;
<p>The above is the solution if "Read timeout error" is seen on the client side.
  In all other cases, a default GT3.2 container with CAS service deployed should
  suffice.
<h3>Running test targets </h3>
<blockquote>
  <p>All tests use the stress framework in GT3.2 core. For more details, refer to test
    documentation in GT3.2 distribution. All targets have the following options:
  </p>
  <ul>
    <li>-Dstress.threads = number of threads </li>
    <li>-Dstress.processes = number of processes <br>
    </li>
    <li>-Dstress.concurrent = set to "yes" or "no" </li>
  </ul>
  <p>In each case the output is dumped as XML file in the directory from which the
    test is run.
  </p>
  <h4>Basic Query tests </h4>
  <p>Running the following target after setting up the database and GT3.2 container
    runs a test that measures time taken for a call to get the CAS nickname of
    the user. ant basicQueryStress -Dstress.threads=300 -Dstress.processes=1
    -Dstress.concurrent=yes
  </p>
  <h4>Query tests </h4>
  <p>Running the following target after setting up the database and GT3.2 container
      runs a test that measures time taken for getting all applicable policies
      of the user. ant queryStress -Dstress.threads=300 -Dstress.processes=1
      -Dstress.concurrent=no
  </p>
  <h4>Credential tests </h4>
  <p>Running the following target after setting up the database and GT3.2 container
      runs a test that measures time taken for generating credential of all policies
      of user. ant credentialStress -Dstress.threads=200 -Dstress.processes=1
      -Dstress.concurrent=yes
  </p>
  <h4>Size of Credential </h4>
  <p>This test is used to ensure that credentials of large sizes can be generated.
      To run this test, set up the data base using the "populateDB" target with
      options "large largeCred". This will ensure that the credential returned
      on running the following is around 70K. This test requires that the timeout
      be set to a high value as descibed <a href="#gt3Cont">here </a>. Since
      this is a test of large credential generation, it maybe prudent to just
      have one or few threads execution, rather than many. ant credentialStress
    -Dstress.threads=1 -Dstress.processes=1 -Dstress.concurrent=no Infrasture
    overhead test <br>
  </p>
  <p>The <em>whoami </em> method on CAS port was overridden to just return a
    dummy string without any processing. The above described "Basic Query Test" was
    done to measure performance with 200 serial and concurrent client. On serial
    testing, time taken was 252ms (252) and on concurrent testing it was 187ms
    (34209). So it appears that irrespective of the application code, the infrastructure
    takes a considerably long time on concurrent calls. </p>
</blockquote>
<?php include("http://www-unix.globus.org/include/globus_footer.inc"); ?>
