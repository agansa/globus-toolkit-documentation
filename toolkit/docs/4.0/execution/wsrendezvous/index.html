  
<h1>WS Rendezvous</h1>
<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#design">Design and Interactions</a></li>
  <li><a href="#implementing">Implementing Rendezvous clients</a></li>   
</ul>
<h2><a name="introduction"></a>Introduction</h2>
<p>

</p>

<h2><a name="#design"></a>Design and Interactions</h2>
<p>
Rendezvous port type
<p>
<h3>Flow of control</h3>
Given a set of tasks (e.g. processes) at the level 0 (leaf) of a hierarchy of 
execution units (e.g. jobs or multijobs) layered in a number of levels 
mapped to a corresponding hierarchy of rendezvous resources, tasks will rendezvous with 
each other using the rendezvous hierarchy.<p>
For each level 1 execution unit (e.g job) or rendezvous:
<ol>
<li>the controlling task (e.g. process 0) subscribes for notifications for when the 
    rendezvous is complete 
    (optimization: this step is not needed if there is only one task)</li>
<li>each task (e.g. process) registers its data to the rendezvous resource of level 1 (e.g. GRAM job)</li>
<li>when/if the controlling task (e.g. process 0) gets a notification 
    of rendezvous completion:<p>
    <b>if</b> there exists a <i>higher-level rendezvous (e.g. multijob)</i>
    <b>then</b> the controlling task (e.g. process 0) makes remote calls to it 
    in order to:
    <ol>
        <li>subscribe for notifications for when that rendezvous is complete</li>
        <li>register the data for the entire set of tasks</li>
    </ol>
</li>
<li>the flow can iterate if there are more rendezvous levels</li>
</ol>

<img src="RendezVous_Collaboration.gif">

<p>
<h3>Application to MPI jobs</h3>

Acquisition of the contact data for the processes in a job is 
different than the actual interprocess contact, which is always 
done through MPI. Interactions depend on the usage of native MPI or 
non-native MPI. There are two cases:<p>
<ul>
<li>
non-native MPI: process 0 uses the GRAM Rendezvous feature in order to 
do interprocess data exchange, i.e acquiring processes contact data. </li>
<li>
native MPI: process 0 gets all siblings contact through native MPI. There 
is no need for a subjob-level rendezvous her. Only a multijob rendezvous 
is used (if there is a multijob).</li>
</ul>
<h3>Data format</h3>

The input format of the binary data to register is recursive:
<ul>
<li>level 0 data :== byteCount SPACE bytes  with byteCount an ASCII encoded byte array</li>
<li>level 1 data :== dataCount SPACE (level 0 data)*</li>
<li>level 2 data :== dataCount SPACE (level 1 data)*</li>
<li>...
</ul>

The "level 0 data" is the data of a task at level 0 of the rendezvous hierarchy 
(e.g. the data for a subjob process).
<p>
The generic form is:
<ul>
<li>level 0 data :== byteCount SPACE bytes</li>
<li>level n data :== dataCount SPACE (level n-1 data)*  with n >=1</li>
</ul>

The level n data with n >=1 is the aggregation of all the registered data sets 
of level n-1 (for instance in a GRAM job, level 1 is the level of the job and 
its data is the aggregation, according to the format defined above, of all the 
data sets for every processes started by the job).
<p>
The format of the data shipped within a notification of rendezvous completion 
is the "level n data" with n >= 1 (e.g. the aggregated data at level n).
<p>
Example:
<ul>
<li> process data :== byteCount SPACE bytes</li>
<li>  subjob data :== processCount SPACE (process data)*</li>
<li>multijob data :== subjobCount SPACE (subjob data)*</li>
<li>...
</ul>
<p>
<h2><a name="#implementing"></a>Implementing Rendezvous clients</h2>
Implementing a Rendezvous client (for instance a program executed as a 
computational job via GRAM and that needs to use GRAM built-in Rendezvous capabilities) 
implies the coding of remote calls from the client to the Rendezvous service/resource 
pairs via local calls to stubs generated by the tooling. Two kinds of calls must be 
performed:
<ol>
<li>subscribe to the rendezvous for notifications:</li>
<li>register data with the rendezvous:</li>
</ol>

<h3>In C</h3>

<h3>In Java</h3>
